{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJh442TxC0t5",
        "outputId": "853a98bf-b057-45a7-b81c-88840f43e237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JJ4behDVBlWy",
        "outputId": "bad550e2-b2a1-4fc1-f522-6eb351b6a424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from efficientnet_pytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->efficientnet_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->efficientnet_pytorch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=49da00e549e4e697a09089fb3f8f08aa1b2b3d89569f1791736ad58014e3d9d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/6f/9b/231a832f811ab6ebb1b32455b177ffc6b8b1cd8de19de70c09\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet_pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed efficientnet_pytorch-0.7.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install efficientnet_pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n"
      ],
      "metadata": {
        "id": "thMjnq2FCIZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RetinalDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.data.iloc[idx]['ID']\n",
        "        img_path = os.path.join(self.root_dir, f\"{img_id}.png\")\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.data.iloc[idx]['Disease_Risk']\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "-IdqU1RCCORF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((260, 260)),  # EfficientNet B2 input size is 260x260\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Standard normalization\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = RetinalDataset(\n",
        "    csv_file='/content/drive/MyDrive/eye_dataset/Training_Set/normalities_prob.csv',\n",
        "    root_dir='/content/drive/MyDrive/eye_dataset/Training_Set/Training',\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "val_dataset = RetinalDataset(\n",
        "    csv_file='/content/drive/MyDrive/eye_dataset/Evaluation_Set/normalities_prob_val.csv',\n",
        "    root_dir='/content/drive/MyDrive/eye_dataset/Evaluation_Set/Validation',\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_dataset=RetinalDataset(\n",
        "    csv_file='/content/drive/MyDrive/eye_dataset/Test_Set/normalities_prob.csv',\n",
        "    root_dir='/content/drive/MyDrive/eye_dataset/Test_Set/Test',\n",
        "    transform=transform\n",
        "\n",
        ")\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "8uBYrSWVCRFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the subset from the val_loader\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,Subset\n",
        "\n",
        "indices= list(range(160));\n",
        "\n",
        "val_subset_dataset= Subset(val_dataset,indices);\n",
        "\n",
        "val_subset_loader=DataLoader(val_subset_dataset,batch_size=16,shuffle=False,num_workers=2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S0S6vU5yXmEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "print(len(val_dataset))\n",
        "print(len(test_dataset))\n",
        "print(len(val_subset_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC-A-oStVhtR",
        "outputId": "26e8bc96-55e0-4e7f-b104-0e1caaf44ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1920\n",
            "640\n",
            "640\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load EfficientNet B2\n",
        "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
        "\n",
        "# Modify the final fully connected layer\n",
        "model._fc = nn.Linear(model._fc.in_features, 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNuEutYKCTV5",
        "outputId": "229e2949-9154-46c6-8a9f-8c6c3c49458b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b2-8bb594d6.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b2-8bb594d6.pth\n",
            "100%|██████████| 35.1M/35.1M [00:00<00:00, 126MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()  # because we have 1 output node\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n"
      ],
      "metadata": {
        "id": "pDNmGQbTCUvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pBTbb3UWucp",
        "outputId": "c56a53a1-4e8e-4665-d7bd-c83ffa3b39db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_mfhKSLcc-r",
        "outputId": "8cbe403d-e56d-4b45-94e9-ea0fec8c3c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.26.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "zq7jFH0dcfnM",
        "outputId": "8f799890-b909-4057-da7e-3ae2c1f1366c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjeevan-neupane002\u001b[0m (\u001b[33mjeevan-neupane002-nepal-applied-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "print(len(val_dataset))\n",
        "print(len(val_subset_dataset))\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEnoi25AioQP",
        "outputId": "868c4bab-ec64-46b8-aedb-d12b08edfcbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1920\n",
            "640\n",
            "160\n",
            "640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(project=\"Eye_Disease_Prediction_1\")\n",
        "\n",
        "# Training settings\n",
        "num_epochs = 100\n",
        "best_val_accuracy = 0.0\n",
        "\n",
        "# Early Stopping settings\n",
        "early_stopping_patience = 5    # Stop after 5 bad epochs\n",
        "early_stopping_delta = 0.001   # Require at least this much improvement\n",
        "early_stopping_counter = 0     # How many bad epochs so far\n",
        "\n",
        "# Save dataset lengths\n",
        "train_dataset_len = len(train_dataset)\n",
        "val_dataset_len = len(val_dataset)\n",
        "\n",
        "# Define the number of batches after which to trigger validation\n",
        "validation_interval = 20  # Example: run validation every 20 batches\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} Training\", ncols=100)\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader_tqdm):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device).unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_size = images.size(0)\n",
        "        train_loss += loss.item() * batch_size\n",
        "\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        train_correct += (preds == labels.bool()).sum().item()\n",
        "        train_total += batch_size\n",
        "\n",
        "        # Log train batch loss\n",
        "        wandb.log({\n",
        "            'train_loss_batch': loss.item(),\n",
        "            'train_accuracy_batch': train_correct / train_total  # Use accumulated batch accuracy\n",
        "        }, step=batch_idx + 1)  # Use batch index for x-axis in the log\n",
        "\n",
        "        # Update progress bar\n",
        "        train_loader_tqdm.set_postfix(train_loss=loss.item())\n",
        "        val_counter=0;\n",
        "\n",
        "        # --- Perform validation after a fixed number of batches ---\n",
        "        if (batch_idx + 1) % validation_interval == 0:\n",
        "            # Validation loop\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            val_loader_tqdm = tqdm(val_subset_loader, desc=f\"Validation after {batch_idx+1} batches\", ncols=100)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for val_images, val_labels in val_loader_tqdm:\n",
        "                    val_images = val_images.to(device)\n",
        "                    val_labels = val_labels.to(device).unsqueeze(1)\n",
        "\n",
        "                    val_outputs = model(val_images)\n",
        "\n",
        "                    val_loss_batch = criterion(val_outputs, val_labels)\n",
        "                    batch_size = val_images.size(0)\n",
        "                    val_loss += val_loss_batch.item() * batch_size\n",
        "\n",
        "                    val_preds = torch.sigmoid(val_outputs) > 0.5\n",
        "                    val_correct += (val_preds == val_labels.bool()).sum().item()\n",
        "                    val_total += batch_size\n",
        "\n",
        "                    # Log val batch loss\n",
        "                    val_counter+=1;\n",
        "                    wandb.log({'val_subset_loss_batch': val_loss_batch.item()},step=val_counter);\n",
        "\n",
        "                    # Update progress bar\n",
        "                    val_loader_tqdm.set_postfix(val_loss=val_loss_batch.item())\n",
        "\n",
        "            # Validation epoch metrics after the fixed number of batches\n",
        "            val_loss /= val_dataset_len\n",
        "            val_accuracy = val_correct / val_total\n",
        "\n",
        "            # Log val epoch metrics\n",
        "            wandb.log({\n",
        "                'val_subset_loss_epoch': val_loss,\n",
        "                'val_subset_accuracy_epoch': val_accuracy\n",
        "            }, step=batch_idx + 1)\n",
        "\n",
        "            # Print validation results after fixed batches\n",
        "            print(f\"Validation after {batch_idx+1}/{len(train_loader)} batches: \"\n",
        "                  f\"Val Loss: {val_loss:.4f}  Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "    # --- Perform validation after each epoch ---\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} Validation\", ncols=100)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_images, val_labels in val_loader_tqdm:\n",
        "            val_images = val_images.to(device)\n",
        "            val_labels = val_labels.to(device).unsqueeze(1)\n",
        "\n",
        "            val_outputs = model(val_images)\n",
        "\n",
        "            val_loss_batch = criterion(val_outputs, val_labels)\n",
        "            batch_size = val_images.size(0)\n",
        "            val_loss += val_loss_batch.item() * batch_size\n",
        "\n",
        "            val_preds = torch.sigmoid(val_outputs) > 0.5\n",
        "            val_correct += (val_preds == val_labels.bool()).sum().item()\n",
        "            val_total += batch_size\n",
        "\n",
        "            # Log val batch loss\n",
        "            wandb.log({'val_loss_batch': val_loss_batch.item()})\n",
        "\n",
        "            # Update progress bar\n",
        "            val_loader_tqdm.set_postfix(val_loss=val_loss_batch.item())\n",
        "\n",
        "    # Validation epoch metrics after the entire epoch\n",
        "    val_loss /= val_dataset_len\n",
        "    val_accuracy = val_correct / val_total\n",
        "\n",
        "    # Log val epoch metrics\n",
        "    wandb.log({\n",
        "        'val_loss_epoch': val_loss,\n",
        "        'val_accuracy_epoch': val_accuracy\n",
        "    }, step=epoch + 1)  # Use epoch number for x-axis in the log\n",
        "\n",
        "    # Print validation results after the epoch\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "          f\"Train Loss: {train_loss/train_dataset_len:.4f}  Train Acc: {train_correct/train_total:.4f} \"\n",
        "          f\"Val Loss: {val_loss:.4f}  Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "    # --- Best Model Saving and Early Stopping Check ---\n",
        "    if val_accuracy > best_val_accuracy + early_stopping_delta:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/retinal_classification_trained/best_model.pth\")\n",
        "        print(f\"✅ Best model saved with Val Acc: {best_val_accuracy:.4f}\")\n",
        "        early_stopping_counter = 0\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "        print(f\"⚠️ No improvement in Val Acc for {early_stopping_counter} epoch(s).\")\n",
        "\n",
        "        if early_stopping_counter >= early_stopping_patience:\n",
        "            print(\"⏹ Early stopping triggered! Training stopped.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ypx7ZVpfDQCs",
        "outputId": "5799b2aa-fdc4-426e-fbf9-bf0091b1154d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250428_084903-k0ql802l</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jeevan-neupane002-nepal-applied-/Eye_Disease_Prediction_1/runs/k0ql802l' target=\"_blank\">worldly-silence-1</a></strong> to <a href='https://wandb.ai/jeevan-neupane002-nepal-applied-/Eye_Disease_Prediction_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jeevan-neupane002-nepal-applied-/Eye_Disease_Prediction_1' target=\"_blank\">https://wandb.ai/jeevan-neupane002-nepal-applied-/Eye_Disease_Prediction_1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jeevan-neupane002-nepal-applied-/Eye_Disease_Prediction_1/runs/k0ql802l' target=\"_blank\">https://wandb.ai/jeevan-neupane002-nepal-applied-/Eye_Disease_Prediction_1/runs/k0ql802l</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 Training:  16%|███▍                  | 19/120 [01:24<06:02,  3.58s/it, train_loss=0.434]\n",
            "Validation after 20 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 20 batches:   0%|                           | 0/10 [00:12<?, ?it/s, val_loss=0.588]\u001b[A\n",
            "Validation after 20 batches:  10%|█▉                 | 1/10 [00:12<01:53, 12.58s/it, val_loss=0.588]\u001b[A\n",
            "Validation after 20 batches:  10%|█▉                 | 1/10 [00:12<01:53, 12.58s/it, val_loss=0.624]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:  10%|█▉                 | 1/10 [00:19<01:53, 12.58s/it, val_loss=0.582]\u001b[A\n",
            "Validation after 20 batches:  30%|█████▋             | 3/10 [00:19<00:41,  5.99s/it, val_loss=0.582]\u001b[A\n",
            "Validation after 20 batches:  30%|█████▋             | 3/10 [00:20<00:41,  5.99s/it, val_loss=0.609]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:  30%|█████▋             | 3/10 [00:26<00:41,  5.99s/it, val_loss=0.612]\u001b[A\n",
            "Validation after 20 batches:  50%|█████████▌         | 5/10 [00:26<00:23,  4.72s/it, val_loss=0.612]\u001b[A\n",
            "Validation after 20 batches:  50%|██████████          | 5/10 [00:27<00:23,  4.72s/it, val_loss=0.56]\u001b[A\n",
            "Validation after 20 batches:  50%|█████████▌         | 5/10 [00:33<00:23,  4.72s/it, val_loss=0.539]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:33<00:12,  4.09s/it, val_loss=0.539]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:33<00:12,  4.09s/it, val_loss=0.585]\u001b[A\n",
            "Validation after 20 batches:  80%|███████████████▏   | 8/10 [00:33<00:06,  3.18s/it, val_loss=0.585]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:  80%|███████████████▏   | 8/10 [00:40<00:06,  3.18s/it, val_loss=0.569]\u001b[A\n",
            "Validation after 20 batches:  90%|█████████████████  | 9/10 [00:40<00:04,  4.11s/it, val_loss=0.569]\u001b[A\n",
            "Validation after 20 batches: 100%|██████████████████| 10/10 [00:40<00:00,  4.06s/it, val_loss=0.575]\n",
            "Epoch 1/100 Training:  17%|███▋                  | 20/120 [02:04<27:36, 16.56s/it, train_loss=0.434]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 20/120 batches: Val Loss: 0.1460  Val Acc: 0.9250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 Training:  20%|████▍                 | 24/120 [02:05<06:38,  4.15s/it, train_loss=0.407]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 1/100 Training:  32%|███████▏              | 39/120 [03:09<05:40,  4.21s/it, train_loss=0.314]\n",
            "Validation after 40 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 40 batches:   0%|                           | 0/10 [00:03<?, ?it/s, val_loss=0.112]\u001b[A\n",
            "Validation after 40 batches:  10%|█▉                 | 1/10 [00:03<00:35,  3.91s/it, val_loss=0.112]\u001b[A\n",
            "Validation after 40 batches:  10%|█▉                 | 1/10 [00:04<00:35,  3.91s/it, val_loss=0.174]\u001b[A\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:04<00:13,  1.72s/it, val_loss=0.174]\u001b[A\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:08<00:13,  1.72s/it, val_loss=0.122]\u001b[A\n",
            "Validation after 40 batches:  30%|█████▋             | 3/10 [00:08<00:20,  2.90s/it, val_loss=0.122]\u001b[A\n",
            "Validation after 40 batches:  30%|█████▍            | 3/10 [00:08<00:20,  2.90s/it, val_loss=0.0827]\u001b[A\n",
            "Validation after 40 batches:  40%|███████▏          | 4/10 [00:08<00:10,  1.81s/it, val_loss=0.0827]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 40. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 40. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 40. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 40. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:  40%|███████▌           | 4/10 [00:11<00:10,  1.81s/it, val_loss=0.174]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████▌         | 5/10 [00:11<00:11,  2.27s/it, val_loss=0.174]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████         | 5/10 [00:11<00:11,  2.27s/it, val_loss=0.0682]\u001b[A\n",
            "Validation after 40 batches:  60%|██████████▊       | 6/10 [00:11<00:06,  1.54s/it, val_loss=0.0682]\u001b[A\n",
            "Validation after 40 batches:  60%|██████████▊       | 6/10 [00:14<00:06,  1.54s/it, val_loss=0.0794]\u001b[A\n",
            "Validation after 40 batches:  70%|████████████▌     | 7/10 [00:14<00:05,  1.95s/it, val_loss=0.0794]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:14<00:05,  1.95s/it, val_loss=0.172]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:17<00:05,  1.95s/it, val_loss=0.148]\u001b[A\n",
            "Validation after 40 batches:  90%|█████████████████  | 9/10 [00:17<00:01,  1.65s/it, val_loss=0.148]\u001b[A\n",
            "Validation after 40 batches: 100%|██████████████████| 10/10 [00:17<00:00,  1.73s/it, val_loss=0.208]\n",
            "Epoch 1/100 Training:  33%|███████▎              | 40/120 [03:27<11:34,  8.69s/it, train_loss=0.314]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 40/120 batches: Val Loss: 0.0335  Val Acc: 0.9500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 Training:  36%|███████▉              | 43/120 [03:27<04:01,  3.14s/it, train_loss=0.333]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 40. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 40. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 40. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 40. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 40. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 40. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 1/100 Training:  49%|██████████▊           | 59/120 [04:32<04:00,  3.94s/it, train_loss=0.204]\n",
            "Validation after 60 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 60 batches:   0%|                            | 0/10 [00:03<?, ?it/s, val_loss=0.14]\u001b[A\n",
            "Validation after 60 batches:  10%|██                  | 1/10 [00:03<00:33,  3.74s/it, val_loss=0.14]\u001b[A\n",
            "Validation after 60 batches:  10%|█▉                 | 1/10 [00:03<00:33,  3.74s/it, val_loss=0.201]\u001b[A\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:03<00:13,  1.67s/it, val_loss=0.201]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 60. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 60. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:08<00:13,  1.67s/it, val_loss=0.135]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▋             | 3/10 [00:08<00:19,  2.82s/it, val_loss=0.135]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▍            | 3/10 [00:08<00:19,  2.82s/it, val_loss=0.0729]\u001b[A\n",
            "Validation after 60 batches:  40%|███████▏          | 4/10 [00:08<00:10,  1.76s/it, val_loss=0.0729]\u001b[A\n",
            "Validation after 60 batches:  40%|████████            | 4/10 [00:11<00:10,  1.76s/it, val_loss=0.21]\u001b[A\n",
            "Validation after 60 batches:  50%|██████████          | 5/10 [00:11<00:11,  2.29s/it, val_loss=0.21]\u001b[A\n",
            "Validation after 60 batches:  50%|█████████         | 5/10 [00:11<00:11,  2.29s/it, val_loss=0.0872]\u001b[A\n",
            "Validation after 60 batches:  60%|██████████▊       | 6/10 [00:11<00:06,  1.55s/it, val_loss=0.0872]\u001b[A\n",
            "Validation after 60 batches:  60%|██████████▊       | 6/10 [00:14<00:06,  1.55s/it, val_loss=0.0954]\u001b[A\n",
            "Validation after 60 batches:  70%|████████████▌     | 7/10 [00:14<00:06,  2.13s/it, val_loss=0.0954]\u001b[A\n",
            "Validation after 60 batches:  70%|█████████████▎     | 7/10 [00:15<00:06,  2.13s/it, val_loss=0.152]\u001b[A\n",
            "Validation after 60 batches:  80%|███████████████▏   | 8/10 [00:15<00:02,  1.49s/it, val_loss=0.152]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 60. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 60. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 60. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 60. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 60. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 60. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:  80%|███████████████▏   | 8/10 [00:17<00:02,  1.49s/it, val_loss=0.136]\u001b[A\n",
            "Validation after 60 batches:  90%|█████████████████  | 9/10 [00:17<00:01,  1.80s/it, val_loss=0.136]\u001b[A\n",
            "Validation after 60 batches: 100%|██████████████████| 10/10 [00:17<00:00,  1.77s/it, val_loss=0.244]\n",
            "Epoch 1/100 Training:  50%|███████████           | 60/120 [04:50<09:00,  9.01s/it, train_loss=0.204]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 60/120 batches: Val Loss: 0.0368  Val Acc: 0.9313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 Training:  53%|███████████▋          | 64/120 [04:55<03:16,  3.51s/it, train_loss=0.223]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 60. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 60. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 1/100 Training:  66%|██████████████▍       | 79/120 [05:59<03:16,  4.80s/it, train_loss=0.331]\n",
            "Validation after 80 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 80 batches:   0%|                           | 0/10 [00:04<?, ?it/s, val_loss=0.204]\u001b[A\n",
            "Validation after 80 batches:  10%|█▉                 | 1/10 [00:04<00:44,  4.96s/it, val_loss=0.204]\u001b[A\n",
            "Validation after 80 batches:  10%|█▉                 | 1/10 [00:05<00:44,  4.96s/it, val_loss=0.351]\u001b[A\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:05<00:16,  2.11s/it, val_loss=0.351]\u001b[A\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:07<00:16,  2.11s/it, val_loss=0.241]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▋             | 3/10 [00:07<00:16,  2.39s/it, val_loss=0.241]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▋             | 3/10 [00:07<00:16,  2.39s/it, val_loss=0.261]\u001b[A\n",
            "Validation after 80 batches:  40%|███████▌           | 4/10 [00:07<00:08,  1.50s/it, val_loss=0.261]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 80. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 80. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 80. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 80. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 80 batches:  40%|████████            | 4/10 [00:10<00:08,  1.50s/it, val_loss=0.27]\u001b[A\n",
            "Validation after 80 batches:  50%|██████████          | 5/10 [00:10<00:10,  2.03s/it, val_loss=0.27]\u001b[A\n",
            "Validation after 80 batches:  50%|█████████▌         | 5/10 [00:11<00:10,  2.03s/it, val_loss=0.126]\u001b[A\n",
            "Validation after 80 batches:  60%|███████████▍       | 6/10 [00:11<00:05,  1.38s/it, val_loss=0.126]\u001b[A\n",
            "Validation after 80 batches:  60%|███████████▍       | 6/10 [00:14<00:05,  1.38s/it, val_loss=0.136]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:14<00:06,  2.19s/it, val_loss=0.136]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:15<00:06,  2.19s/it, val_loss=0.154]\u001b[A\n",
            "Validation after 80 batches:  80%|███████████████▏   | 8/10 [00:15<00:03,  1.56s/it, val_loss=0.154]\u001b[A\n",
            "Validation after 80 batches:  80%|███████████████▏   | 8/10 [00:19<00:03,  1.56s/it, val_loss=0.186]\u001b[A\n",
            "Validation after 80 batches:  90%|█████████████████  | 9/10 [00:19<00:02,  2.48s/it, val_loss=0.186]\u001b[A\n",
            "Validation after 80 batches: 100%|██████████████████| 10/10 [00:19<00:00,  1.97s/it, val_loss=0.308]\n",
            "Epoch 1/100 Training:  67%|██████████████▋       | 80/120 [06:18<06:14,  9.36s/it, train_loss=0.331]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 80/120 batches: Val Loss: 0.0559  Val Acc: 0.9250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 Training:  68%|███████████████       | 82/120 [06:19<02:58,  4.71s/it, train_loss=0.433]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 80. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 80. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 80. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 80. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 80. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 80. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 1/100 Training:  82%|██████████████████▏   | 99/120 [07:27<01:44,  4.98s/it, train_loss=0.216]\n",
            "Validation after 100 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 100 batches:   0%|                          | 0/10 [00:03<?, ?it/s, val_loss=0.212]\u001b[A\n",
            "Validation after 100 batches:  10%|█▊                | 1/10 [00:03<00:28,  3.21s/it, val_loss=0.212]\u001b[A\n",
            "Validation after 100 batches:  10%|█▊                | 1/10 [00:03<00:28,  3.21s/it, val_loss=0.279]\u001b[A\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:03<00:11,  1.39s/it, val_loss=0.279]\u001b[A\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:06<00:11,  1.39s/it, val_loss=0.252]\u001b[A\n",
            "Validation after 100 batches:  30%|█████▍            | 3/10 [00:06<00:15,  2.19s/it, val_loss=0.252]\u001b[A\n",
            "Validation after 100 batches:  30%|█████            | 3/10 [00:06<00:15,  2.19s/it, val_loss=0.0886]\u001b[A\n",
            "Validation after 100 batches:  40%|██████▊          | 4/10 [00:06<00:08,  1.37s/it, val_loss=0.0886]\u001b[A\n",
            "Validation after 100 batches:  40%|███████▌           | 4/10 [00:11<00:08,  1.37s/it, val_loss=0.34]\u001b[A\n",
            "Validation after 100 batches:  50%|█████████▌         | 5/10 [00:11<00:13,  2.72s/it, val_loss=0.34]\u001b[A\n",
            "Validation after 100 batches:  50%|█████████         | 5/10 [00:11<00:13,  2.72s/it, val_loss=0.121]\u001b[A\n",
            "Validation after 100 batches:  60%|██████████▊       | 6/10 [00:11<00:07,  1.86s/it, val_loss=0.121]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 100. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 100. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 100. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 100. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 100. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 100. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 100 batches:  60%|██████████▊       | 6/10 [00:14<00:07,  1.86s/it, val_loss=0.159]\u001b[A\n",
            "Validation after 100 batches:  70%|████████████▌     | 7/10 [00:14<00:06,  2.20s/it, val_loss=0.159]\u001b[A\n",
            "Validation after 100 batches:  70%|█████████████▎     | 7/10 [00:15<00:06,  2.20s/it, val_loss=0.11]\u001b[A\n",
            "Validation after 100 batches:  80%|███████████████▏   | 8/10 [00:15<00:03,  1.61s/it, val_loss=0.11]\u001b[A\n",
            "Validation after 100 batches:  80%|██████████████▍   | 8/10 [00:17<00:03,  1.61s/it, val_loss=0.158]\u001b[A\n",
            "Validation after 100 batches:  90%|████████████████▏ | 9/10 [00:17<00:01,  1.80s/it, val_loss=0.158]\u001b[A\n",
            "Validation after 100 batches:  90%|█████████████████  | 9/10 [00:17<00:01,  1.80s/it, val_loss=0.38]\u001b[A\n",
            "Validation after 100 batches: 100%|██████████████████| 10/10 [00:17<00:00,  1.79s/it, val_loss=0.38]\n",
            "Epoch 1/100 Training:  83%|█████████████████▌   | 100/120 [07:45<02:58,  8.94s/it, train_loss=0.216]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 100/120 batches: Val Loss: 0.0525  Val Acc: 0.8750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 Training:  86%|██████████████████   | 103/120 [07:48<01:08,  4.06s/it, train_loss=0.389]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 100. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 100. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 100. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 100. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 1/100 Training:  99%|████████████████████▊| 119/120 [08:56<00:03,  3.08s/it, train_loss=0.285]\n",
            "Validation after 120 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 120 batches:   0%|                         | 0/10 [00:03<?, ?it/s, val_loss=0.0192]\u001b[A\n",
            "Validation after 120 batches:  10%|█▋               | 1/10 [00:03<00:34,  3.86s/it, val_loss=0.0192]\u001b[A\n",
            "Validation after 120 batches:  10%|█▋               | 1/10 [00:03<00:34,  3.86s/it, val_loss=0.0788]\u001b[A\n",
            "Validation after 120 batches:  20%|███▍             | 2/10 [00:03<00:13,  1.67s/it, val_loss=0.0788]\u001b[A\n",
            "Validation after 120 batches:  20%|███▍             | 2/10 [00:06<00:13,  1.67s/it, val_loss=0.0691]\u001b[A\n",
            "Validation after 120 batches:  30%|█████            | 3/10 [00:06<00:13,  1.91s/it, val_loss=0.0691]\u001b[A\n",
            "Validation after 120 batches:  30%|████▊           | 3/10 [00:06<00:13,  1.91s/it, val_loss=0.00322]\u001b[A\n",
            "Validation after 120 batches:  30%|█████            | 3/10 [00:08<00:13,  1.91s/it, val_loss=0.0247]\u001b[A\n",
            "Validation after 120 batches:  50%|████████▌        | 5/10 [00:08<00:07,  1.42s/it, val_loss=0.0247]\u001b[A\n",
            "Validation after 120 batches:  50%|████████▌        | 5/10 [00:08<00:07,  1.42s/it, val_loss=0.0171]\u001b[A\n",
            "Validation after 120 batches:  50%|████████▌        | 5/10 [00:10<00:07,  1.42s/it, val_loss=0.0659]\u001b[A\n",
            "Validation after 120 batches:  70%|███████████▉     | 7/10 [00:10<00:03,  1.26s/it, val_loss=0.0659]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:10<00:03,  1.26s/it, val_loss=0.192]\u001b[A\n",
            "Validation after 120 batches:  80%|██████████████▍   | 8/10 [00:10<00:01,  1.02it/s, val_loss=0.192]\u001b[A\n",
            "Validation after 120 batches:  80%|███████████████▏   | 8/10 [00:12<00:01,  1.02it/s, val_loss=0.28]\u001b[A\n",
            "Validation after 120 batches:  90%|█████████████████  | 9/10 [00:12<00:01,  1.21s/it, val_loss=0.28]\u001b[A\n",
            "Validation after 120 batches: 100%|█████████████████| 10/10 [00:12<00:00,  1.25s/it, val_loss=0.175]\n",
            "Epoch 1/100 Training: 100%|█████████████████████| 120/120 [09:09<00:00,  4.58s/it, train_loss=0.285]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 120/120 batches: Val Loss: 0.0231  Val Acc: 0.9688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/100 Validation:   0%|                                                | 0/40 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 120. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 120. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 120. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 120. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 120. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 120. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 120. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 120. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 120. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 120. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 1/100 Validation: 100%|███████████████████████████| 40/40 [02:28<00:00,  3.71s/it, val_loss=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] Train Loss: 0.3767  Train Acc: 0.8359 Val Loss: 0.3137  Val Acc: 0.8250\n",
            "✅ Best model saved with Val Acc: 0.8250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100 Training:   0%|                                                 | 0/120 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:   3%|▊                      | 4/120 [00:10<04:28,  2.32s/it, train_loss=0.378]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:   8%|█▋                     | 9/120 [00:18<03:10,  1.72s/it, train_loss=0.423]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  12%|██▊                   | 15/120 [00:29<02:32,  1.45s/it, train_loss=0.359]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 11 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 12 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 13 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 14 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 15 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  16%|███▋                   | 19/120 [00:39<03:27,  2.05s/it, train_loss=0.32]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 16 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 17 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 18 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 19 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  16%|███▍                  | 19/120 [00:43<03:27,  2.05s/it, train_loss=0.341]\n",
            "Validation after 20 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 20 batches:   0%|                         | 0/10 [00:05<?, ?it/s, val_loss=0.00373]\u001b[A\n",
            "Validation after 20 batches:  10%|█▋               | 1/10 [00:05<00:46,  5.17s/it, val_loss=0.00373]\u001b[A\n",
            "Validation after 20 batches:  10%|█▊                | 1/10 [00:05<00:46,  5.17s/it, val_loss=0.0467]\u001b[A\n",
            "Validation after 20 batches:  20%|███▌              | 2/10 [00:05<00:17,  2.20s/it, val_loss=0.0467]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:  20%|███▌              | 2/10 [00:08<00:17,  2.20s/it, val_loss=0.0422]\u001b[A\n",
            "Validation after 20 batches:  30%|█████▍            | 3/10 [00:08<00:18,  2.68s/it, val_loss=0.0422]\u001b[A\n",
            "Validation after 20 batches:  30%|████▊           | 3/10 [00:08<00:18,  2.68s/it, val_loss=0.000295]\u001b[A\n",
            "Validation after 20 batches:  40%|██████▍         | 4/10 [00:08<00:09,  1.66s/it, val_loss=0.000295]\u001b[A\n",
            "Validation after 20 batches:  40%|██████▊          | 4/10 [00:11<00:09,  1.66s/it, val_loss=0.00443]\u001b[A\n",
            "Validation after 20 batches:  50%|████████▌        | 5/10 [00:11<00:10,  2.19s/it, val_loss=0.00443]\u001b[A\n",
            "Validation after 20 batches:  50%|████████▌        | 5/10 [00:11<00:10,  2.19s/it, val_loss=0.00293]\u001b[A\n",
            "Validation after 20 batches:  60%|██████████▏      | 6/10 [00:11<00:05,  1.49s/it, val_loss=0.00293]\u001b[A\n",
            "Validation after 20 batches:  60%|██████████▊       | 6/10 [00:14<00:05,  1.49s/it, val_loss=0.0418]\u001b[A\n",
            "Validation after 20 batches:  70%|████████████▌     | 7/10 [00:14<00:05,  1.79s/it, val_loss=0.0418]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:14<00:05,  1.79s/it, val_loss=0.351]\u001b[A\n",
            "Validation after 20 batches:  80%|███████████████▏   | 8/10 [00:14<00:02,  1.25s/it, val_loss=0.351]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:  80%|████████████████    | 8/10 [00:16<00:02,  1.25s/it, val_loss=0.43]\u001b[A\n",
            "Validation after 20 batches:  90%|██████████████████  | 9/10 [00:16<00:01,  1.42s/it, val_loss=0.43]\u001b[A\n",
            "Validation after 20 batches: 100%|██████████████████| 10/10 [00:16<00:00,  1.63s/it, val_loss=0.141]\n",
            "Epoch 2/100 Training:  17%|███▋                  | 20/120 [01:00<12:36,  7.57s/it, train_loss=0.341]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 20/120 batches: Val Loss: 0.0266  Val Acc: 0.9688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100 Training:  22%|████▉                  | 26/120 [01:06<03:27,  2.21s/it, train_loss=0.23]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 21 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 22 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 23 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 24 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 25 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 26 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  25%|█████▊                 | 30/120 [01:14<02:46,  1.85s/it, train_loss=0.26]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 27 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 28 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 29 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 30 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  32%|███████▎               | 38/120 [01:29<01:57,  1.43s/it, train_loss=0.58]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 31 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 32 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 33 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 34 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 35 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 36 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 37 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 38 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  32%|███████▏              | 39/120 [01:34<02:18,  1.71s/it, train_loss=0.245]\n",
            "Validation after 40 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 40 batches:   0%|                          | 0/10 [00:04<?, ?it/s, val_loss=0.0984]\u001b[A\n",
            "Validation after 40 batches:  10%|█▊                | 1/10 [00:04<00:43,  4.86s/it, val_loss=0.0984]\u001b[A\n",
            "Validation after 40 batches:  10%|█▉                 | 1/10 [00:04<00:43,  4.86s/it, val_loss=0.198]\u001b[A\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:04<00:16,  2.08s/it, val_loss=0.198]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 39 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:08<00:16,  2.08s/it, val_loss=0.163]\u001b[A\n",
            "Validation after 40 batches:  30%|█████▋             | 3/10 [00:08<00:19,  2.73s/it, val_loss=0.163]\u001b[A\n",
            "Validation after 40 batches:  30%|█████▋             | 3/10 [00:08<00:19,  2.73s/it, val_loss=0.113]\u001b[A\n",
            "Validation after 40 batches:  40%|███████▌           | 4/10 [00:08<00:10,  1.69s/it, val_loss=0.113]\u001b[A\n",
            "Validation after 40 batches:  40%|███████▌           | 4/10 [00:12<00:10,  1.69s/it, val_loss=0.114]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████▌         | 5/10 [00:12<00:11,  2.37s/it, val_loss=0.114]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████         | 5/10 [00:12<00:11,  2.37s/it, val_loss=0.0477]\u001b[A\n",
            "Validation after 40 batches:  60%|██████████▊       | 6/10 [00:12<00:06,  1.60s/it, val_loss=0.0477]\u001b[A\n",
            "Validation after 40 batches:  60%|███████████▍       | 6/10 [00:15<00:06,  1.60s/it, val_loss=0.108]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:15<00:06,  2.14s/it, val_loss=0.108]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:15<00:06,  2.14s/it, val_loss=0.141]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:  70%|██████████████      | 7/10 [00:17<00:06,  2.14s/it, val_loss=0.15]\u001b[A\n",
            "Validation after 40 batches:  90%|██████████████████  | 9/10 [00:17<00:01,  1.58s/it, val_loss=0.15]\u001b[A\n",
            "Validation after 40 batches: 100%|██████████████████| 10/10 [00:17<00:00,  1.76s/it, val_loss=0.252]\n",
            "Epoch 2/100 Training:  33%|███████▎              | 40/120 [01:51<09:44,  7.31s/it, train_loss=0.245]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 40/120 batches: Val Loss: 0.0346  Val Acc: 0.9437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100 Training:  39%|████████▌             | 47/120 [01:57<02:03,  1.69s/it, train_loss=0.246]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 41 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 42 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 43 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 44 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 45 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 46 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 47 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  44%|█████████▋            | 53/120 [02:09<01:53,  1.69s/it, train_loss=0.254]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 48 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 49 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 50 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 51 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 52 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 53 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  48%|██████████▍           | 57/120 [02:19<02:07,  2.03s/it, train_loss=0.339]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 54 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 55 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 56 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 57 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  49%|██████████▊           | 59/120 [02:27<02:08,  2.10s/it, train_loss=0.486]\n",
            "Validation after 60 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 58 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 59 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:   0%|                           | 0/10 [00:06<?, ?it/s, val_loss=0.338]\u001b[A\n",
            "Validation after 60 batches:  10%|█▉                 | 1/10 [00:06<01:00,  6.67s/it, val_loss=0.338]\u001b[A\n",
            "Validation after 60 batches:  10%|█▉                 | 1/10 [00:06<01:00,  6.67s/it, val_loss=0.353]\u001b[A\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:06<00:22,  2.81s/it, val_loss=0.353]\u001b[A\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:09<00:22,  2.81s/it, val_loss=0.343]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▋             | 3/10 [00:09<00:19,  2.86s/it, val_loss=0.343]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▋             | 3/10 [00:09<00:19,  2.86s/it, val_loss=0.182]\u001b[A\n",
            "Validation after 60 batches:  40%|███████▌           | 4/10 [00:09<00:10,  1.78s/it, val_loss=0.182]\u001b[A\n",
            "Validation after 60 batches:  40%|███████▌           | 4/10 [00:12<00:10,  1.78s/it, val_loss=0.397]\u001b[A\n",
            "Validation after 60 batches:  50%|█████████▌         | 5/10 [00:12<00:10,  2.07s/it, val_loss=0.397]\u001b[A\n",
            "Validation after 60 batches:  50%|█████████▌         | 5/10 [00:12<00:10,  2.07s/it, val_loss=0.133]\u001b[A\n",
            "Validation after 60 batches:  60%|███████████▍       | 6/10 [00:12<00:05,  1.43s/it, val_loss=0.133]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:  60%|███████████▍       | 6/10 [00:14<00:05,  1.43s/it, val_loss=0.206]\u001b[A\n",
            "Validation after 60 batches:  70%|█████████████▎     | 7/10 [00:14<00:04,  1.60s/it, val_loss=0.206]\u001b[A\n",
            "Validation after 60 batches:  70%|█████████████▎     | 7/10 [00:14<00:04,  1.60s/it, val_loss=0.112]\u001b[A\n",
            "Validation after 60 batches:  80%|███████████████▏   | 8/10 [00:14<00:02,  1.14s/it, val_loss=0.112]\u001b[A\n",
            "Validation after 60 batches:  80%|███████████████▏   | 8/10 [00:16<00:02,  1.14s/it, val_loss=0.137]\u001b[A\n",
            "Validation after 60 batches:  90%|█████████████████  | 9/10 [00:16<00:01,  1.35s/it, val_loss=0.137]\u001b[A\n",
            "Validation after 60 batches:  90%|█████████████████  | 9/10 [00:16<00:01,  1.35s/it, val_loss=0.469]\u001b[A\n",
            "Validation after 60 batches: 100%|██████████████████| 10/10 [00:16<00:00,  1.68s/it, val_loss=0.469]\n",
            "Epoch 2/100 Training:  50%|███████████           | 60/120 [02:43<07:24,  7.41s/it, train_loss=0.486]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 60/120 batches: Val Loss: 0.0667  Val Acc: 0.8375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100 Training:  54%|███████████▉          | 65/120 [02:49<02:34,  2.81s/it, train_loss=0.173]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 61 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 62 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 63 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 64 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 65 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  58%|████████████▊         | 70/120 [02:58<01:25,  1.71s/it, train_loss=0.147]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 66 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 67 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 68 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 69 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 70 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  63%|█████████████▉        | 76/120 [03:09<01:21,  1.85s/it, train_loss=0.276]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 71 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 72 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 73 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 74 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 75 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 76 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  66%|██████████████▍       | 79/120 [03:18<00:59,  1.45s/it, train_loss=0.207]\n",
            "Validation after 80 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 77 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 78 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 79 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 80 batches:   0%|                           | 0/10 [00:04<?, ?it/s, val_loss=0.199]\u001b[A\n",
            "Validation after 80 batches:  10%|█▉                 | 1/10 [00:04<00:40,  4.53s/it, val_loss=0.199]\u001b[A\n",
            "Validation after 80 batches:  10%|█▉                 | 1/10 [00:04<00:40,  4.53s/it, val_loss=0.294]\u001b[A\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:04<00:15,  1.93s/it, val_loss=0.294]\u001b[A\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:07<00:15,  1.93s/it, val_loss=0.232]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▋             | 3/10 [00:07<00:16,  2.35s/it, val_loss=0.232]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▋             | 3/10 [00:07<00:16,  2.35s/it, val_loss=0.137]\u001b[A\n",
            "Validation after 80 batches:  40%|███████▌           | 4/10 [00:07<00:08,  1.47s/it, val_loss=0.137]\u001b[A\n",
            "Validation after 80 batches:  40%|███████▌           | 4/10 [00:11<00:08,  1.47s/it, val_loss=0.277]\u001b[A\n",
            "Validation after 80 batches:  50%|█████████▌         | 5/10 [00:11<00:10,  2.20s/it, val_loss=0.277]\u001b[A\n",
            "Validation after 80 batches:  50%|█████████         | 5/10 [00:11<00:10,  2.20s/it, val_loss=0.0836]\u001b[A\n",
            "Validation after 80 batches:  60%|██████████▊       | 6/10 [00:11<00:05,  1.50s/it, val_loss=0.0836]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 80 batches:  60%|███████████▍       | 6/10 [00:15<00:05,  1.50s/it, val_loss=0.166]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:15<00:06,  2.30s/it, val_loss=0.166]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:15<00:06,  2.30s/it, val_loss=0.121]\u001b[A\n",
            "Validation after 80 batches:  80%|███████████████▏   | 8/10 [00:15<00:03,  1.60s/it, val_loss=0.121]\u001b[A\n",
            "Validation after 80 batches:  80%|███████████████▏   | 8/10 [00:17<00:03,  1.60s/it, val_loss=0.141]\u001b[A\n",
            "Validation after 80 batches:  90%|█████████████████  | 9/10 [00:17<00:01,  1.69s/it, val_loss=0.141]\u001b[A\n",
            "Validation after 80 batches: 100%|██████████████████| 10/10 [00:17<00:00,  1.73s/it, val_loss=0.406]\n",
            "Epoch 2/100 Training:  67%|██████████████▋       | 80/120 [03:35<05:08,  7.72s/it, train_loss=0.207]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 80/120 batches: Val Loss: 0.0514  Val Acc: 0.8750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100 Training:  72%|███████████████▊      | 86/120 [03:39<00:53,  1.56s/it, train_loss=0.205]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 81 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 82 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 83 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 84 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 85 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 86 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  75%|█████████████████▎     | 90/120 [03:47<01:03,  2.11s/it, train_loss=0.52]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 87 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 88 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 89 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 90 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  80%|██████████████████▍    | 96/120 [03:58<00:39,  1.63s/it, train_loss=0.27]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 91 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 92 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 93 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 94 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 95 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 96 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  82%|██████████████████▏   | 99/120 [04:07<00:49,  2.37s/it, train_loss=0.153]\n",
            "Validation after 100 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 97 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 98 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 99 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 100 batches:   0%|                         | 0/10 [00:04<?, ?it/s, val_loss=0.0736]\u001b[A\n",
            "Validation after 100 batches:  10%|█▋               | 1/10 [00:04<00:44,  4.98s/it, val_loss=0.0736]\u001b[A\n",
            "Validation after 100 batches:  10%|█▊                | 1/10 [00:05<00:44,  4.98s/it, val_loss=0.179]\u001b[A\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:05<00:17,  2.13s/it, val_loss=0.179]\u001b[A\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:10<00:17,  2.13s/it, val_loss=0.113]\u001b[A\n",
            "Validation after 100 batches:  30%|█████▍            | 3/10 [00:10<00:26,  3.82s/it, val_loss=0.113]\u001b[A\n",
            "Validation after 100 batches:  30%|█████            | 3/10 [00:11<00:26,  3.82s/it, val_loss=0.0235]\u001b[A\n",
            "Validation after 100 batches:  40%|██████▊          | 4/10 [00:11<00:14,  2.36s/it, val_loss=0.0235]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 100 batches:  40%|██████▊          | 4/10 [00:14<00:14,  2.36s/it, val_loss=0.0629]\u001b[A\n",
            "Validation after 100 batches:  50%|████████▌        | 5/10 [00:14<00:12,  2.60s/it, val_loss=0.0629]\u001b[A\n",
            "Validation after 100 batches:  50%|████████▌        | 5/10 [00:14<00:12,  2.60s/it, val_loss=0.0129]\u001b[A\n",
            "Validation after 100 batches:  60%|██████████▏      | 6/10 [00:14<00:06,  1.75s/it, val_loss=0.0129]\u001b[A\n",
            "Validation after 100 batches:  60%|██████████▊       | 6/10 [00:16<00:06,  1.75s/it, val_loss=0.105]\u001b[A\n",
            "Validation after 100 batches:  70%|████████████▌     | 7/10 [00:16<00:05,  1.83s/it, val_loss=0.105]\u001b[A\n",
            "Validation after 100 batches:  70%|████████████▌     | 7/10 [00:16<00:05,  1.83s/it, val_loss=0.115]\u001b[A\n",
            "Validation after 100 batches:  80%|██████████████▍   | 8/10 [00:16<00:02,  1.28s/it, val_loss=0.115]\u001b[A\n",
            "Validation after 100 batches:  80%|███████████████▏   | 8/10 [00:18<00:02,  1.28s/it, val_loss=0.19]\u001b[A\n",
            "Validation after 100 batches:  90%|█████████████████  | 9/10 [00:18<00:01,  1.45s/it, val_loss=0.19]\u001b[A\n",
            "Validation after 100 batches: 100%|██████████████████| 10/10 [00:18<00:00,  1.82s/it, val_loss=0.28]\n",
            "Epoch 2/100 Training:  83%|█████████████████▌   | 100/120 [04:25<02:24,  7.22s/it, train_loss=0.153]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 100/120 batches: Val Loss: 0.0288  Val Acc: 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100 Training:  87%|██████████████████▏  | 104/120 [04:26<00:30,  1.92s/it, train_loss=0.299]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 101 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 102 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 103 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 104 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  92%|████████████████████▏ | 110/120 [04:39<00:15,  1.56s/it, train_loss=0.17]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 105 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 106 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 107 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 108 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 109 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 110 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  95%|████████████████████▉ | 114/120 [04:47<00:11,  1.91s/it, train_loss=0.27]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 111 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 112 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 113 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 114 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Training:  99%|█████████████████████▊| 119/120 [04:59<00:01,  1.96s/it, train_loss=0.19]\n",
            "Validation after 120 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 115 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 116 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 117 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 118 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 119 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 120 batches:   0%|                          | 0/10 [00:03<?, ?it/s, val_loss=0.113]\u001b[A\n",
            "Validation after 120 batches:  10%|█▊                | 1/10 [00:03<00:29,  3.33s/it, val_loss=0.113]\u001b[A\n",
            "Validation after 120 batches:  10%|█▊                | 1/10 [00:03<00:29,  3.33s/it, val_loss=0.193]\u001b[A\n",
            "Validation after 120 batches:  20%|███▌              | 2/10 [00:03<00:11,  1.44s/it, val_loss=0.193]\u001b[A\n",
            "Validation after 120 batches:  20%|███▌              | 2/10 [00:05<00:11,  1.44s/it, val_loss=0.142]\u001b[A\n",
            "Validation after 120 batches:  30%|█████▍            | 3/10 [00:05<00:11,  1.62s/it, val_loss=0.142]\u001b[A\n",
            "Validation after 120 batches:  30%|█████            | 3/10 [00:05<00:11,  1.62s/it, val_loss=0.0207]\u001b[A\n",
            "Validation after 120 batches:  30%|█████            | 3/10 [00:07<00:11,  1.62s/it, val_loss=0.0985]\u001b[A\n",
            "Validation after 120 batches:  50%|████████▌        | 5/10 [00:07<00:06,  1.31s/it, val_loss=0.0985]\u001b[A\n",
            "Validation after 120 batches:  50%|████████▌        | 5/10 [00:07<00:06,  1.31s/it, val_loss=0.0307]\u001b[A\n",
            "Validation after 120 batches:  60%|██████████▏      | 6/10 [00:07<00:03,  1.04it/s, val_loss=0.0307]\u001b[A\n",
            "Validation after 120 batches:  60%|██████████▊       | 6/10 [00:09<00:03,  1.04it/s, val_loss=0.126]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:09<00:03,  1.28s/it, val_loss=0.126]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:09<00:03,  1.28s/it, val_loss=0.144]\u001b[A\n",
            "Validation after 120 batches:  80%|██████████████▍   | 8/10 [00:09<00:01,  1.07it/s, val_loss=0.144]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 120 batches:  80%|██████████████▍   | 8/10 [00:11<00:01,  1.07it/s, val_loss=0.233]\u001b[A\n",
            "Validation after 120 batches:  90%|████████████████▏ | 9/10 [00:11<00:01,  1.25s/it, val_loss=0.233]\u001b[A\n",
            "Validation after 120 batches: 100%|█████████████████| 10/10 [00:11<00:00,  1.19s/it, val_loss=0.354]\n",
            "Epoch 2/100 Training: 100%|██████████████████████| 120/120 [05:10<00:00,  2.59s/it, train_loss=0.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 120/120 batches: Val Loss: 0.0364  Val Acc: 0.9313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100 Validation:  15%|███▍                   | 6/40 [00:08<00:36,  1.07s/it, val_loss=0.0307]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 160. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/100 Validation: 100%|███████████████████████| 40/40 [01:18<00:00,  1.96s/it, val_loss=0.443]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/100] Train Loss: 0.2742  Train Acc: 0.8807 Val Loss: 0.2552  Val Acc: 0.8828\n",
            "✅ Best model saved with Val Acc: 0.8828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100 Training:   0%|                                                 | 0/120 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:   5%|█▏                     | 6/120 [00:10<03:10,  1.67s/it, train_loss=0.326]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:   8%|█▊                    | 10/120 [00:20<04:07,  2.25s/it, train_loss=0.233]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  12%|██▌                   | 14/120 [00:29<04:34,  2.59s/it, train_loss=0.323]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 11 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 12 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 13 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 14 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  16%|███▍                  | 19/120 [00:40<03:38,  2.17s/it, train_loss=0.243]\n",
            "Validation after 20 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 15 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 16 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 17 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 18 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 19 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:   0%|                           | 0/10 [00:06<?, ?it/s, val_loss=0.136]\u001b[A\n",
            "Validation after 20 batches:  10%|█▉                 | 1/10 [00:06<00:57,  6.36s/it, val_loss=0.136]\u001b[A\n",
            "Validation after 20 batches:  10%|█▉                 | 1/10 [00:06<00:57,  6.36s/it, val_loss=0.291]\u001b[A\n",
            "Validation after 20 batches:  20%|███▊               | 2/10 [00:06<00:21,  2.68s/it, val_loss=0.291]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:  20%|███▊               | 2/10 [00:10<00:21,  2.68s/it, val_loss=0.196]\u001b[A\n",
            "Validation after 20 batches:  30%|█████▋             | 3/10 [00:10<00:22,  3.28s/it, val_loss=0.196]\u001b[A\n",
            "Validation after 20 batches:  30%|█████▍            | 3/10 [00:10<00:22,  3.28s/it, val_loss=0.0703]\u001b[A\n",
            "Validation after 20 batches:  40%|███████▏          | 4/10 [00:10<00:12,  2.04s/it, val_loss=0.0703]\u001b[A\n",
            "Validation after 20 batches:  40%|███████▏          | 4/10 [00:13<00:12,  2.04s/it, val_loss=0.0884]\u001b[A\n",
            "Validation after 20 batches:  50%|█████████         | 5/10 [00:13<00:11,  2.22s/it, val_loss=0.0884]\u001b[A\n",
            "Validation after 20 batches:  50%|█████████         | 5/10 [00:13<00:11,  2.22s/it, val_loss=0.0107]\u001b[A\n",
            "Validation after 20 batches:  60%|██████████▊       | 6/10 [00:13<00:06,  1.51s/it, val_loss=0.0107]\u001b[A\n",
            "Validation after 20 batches:  60%|███████████▍       | 6/10 [00:16<00:06,  1.51s/it, val_loss=0.155]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:16<00:06,  2.02s/it, val_loss=0.155]\u001b[A\n",
            "Validation after 20 batches:  70%|████████████▌     | 7/10 [00:16<00:06,  2.02s/it, val_loss=0.0944]\u001b[A\n",
            "Validation after 20 batches:  80%|██████████████▍   | 8/10 [00:16<00:02,  1.41s/it, val_loss=0.0944]\u001b[A\n",
            "Validation after 20 batches:  80%|████████████████    | 8/10 [00:19<00:02,  1.41s/it, val_loss=0.22]\u001b[A\n",
            "Validation after 20 batches:  90%|██████████████████  | 9/10 [00:19<00:01,  1.84s/it, val_loss=0.22]\u001b[A\n",
            "Validation after 20 batches: 100%|███████████████████| 10/10 [00:19<00:00,  1.94s/it, val_loss=0.48]\n",
            "Epoch 3/100 Training:  17%|███▋                  | 20/120 [00:59<12:51,  7.71s/it, train_loss=0.243]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 20/120 batches: Val Loss: 0.0436  Val Acc: 0.9125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100 Training:  19%|████▏                 | 23/120 [01:00<04:32,  2.80s/it, train_loss=0.177]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 21 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 22 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 23 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  23%|█████▎                 | 28/120 [01:08<03:07,  2.04s/it, train_loss=0.21]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 24 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 25 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 26 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 27 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 28 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  27%|█████▊                | 32/120 [01:16<02:28,  1.68s/it, train_loss=0.104]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 29 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 30 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 31 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 32 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  30%|██████▌               | 36/120 [01:26<02:43,  1.94s/it, train_loss=0.237]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 33 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 34 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 35 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 36 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  32%|███████▏              | 39/120 [01:36<04:02,  2.99s/it, train_loss=0.244]\n",
            "Validation after 40 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 37 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 38 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 39 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:   0%|                           | 0/10 [00:06<?, ?it/s, val_loss=0.241]\u001b[A\n",
            "Validation after 40 batches:  10%|█▉                 | 1/10 [00:06<00:58,  6.48s/it, val_loss=0.241]\u001b[A\n",
            "Validation after 40 batches:  10%|█▉                 | 1/10 [00:06<00:58,  6.48s/it, val_loss=0.436]\u001b[A\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:06<00:22,  2.77s/it, val_loss=0.436]\u001b[A\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:10<00:22,  2.77s/it, val_loss=0.247]\u001b[A\n",
            "Validation after 40 batches:  30%|█████▋             | 3/10 [00:10<00:21,  3.13s/it, val_loss=0.247]\u001b[A\n",
            "Validation after 40 batches:  30%|█████▋             | 3/10 [00:10<00:21,  3.13s/it, val_loss=0.165]\u001b[A\n",
            "Validation after 40 batches:  40%|███████▌           | 4/10 [00:10<00:11,  1.94s/it, val_loss=0.165]\u001b[A\n",
            "Validation after 40 batches:  40%|███████▌           | 4/10 [00:13<00:11,  1.94s/it, val_loss=0.337]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████▌         | 5/10 [00:13<00:11,  2.39s/it, val_loss=0.337]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████         | 5/10 [00:13<00:11,  2.39s/it, val_loss=0.0855]\u001b[A\n",
            "Validation after 40 batches:  60%|██████████▊       | 6/10 [00:13<00:06,  1.62s/it, val_loss=0.0855]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:  60%|███████████▍       | 6/10 [00:15<00:06,  1.62s/it, val_loss=0.249]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:15<00:05,  1.82s/it, val_loss=0.249]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:15<00:05,  1.82s/it, val_loss=0.105]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:18<00:05,  1.82s/it, val_loss=0.145]\u001b[A\n",
            "Validation after 40 batches:  90%|█████████████████  | 9/10 [00:18<00:01,  1.49s/it, val_loss=0.145]\u001b[A\n",
            "Validation after 40 batches: 100%|██████████████████| 10/10 [00:18<00:00,  1.83s/it, val_loss=0.585]\n",
            "Epoch 3/100 Training:  33%|███████▎              | 40/120 [01:54<10:13,  7.67s/it, train_loss=0.244]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 40/120 batches: Val Loss: 0.0649  Val Acc: 0.8562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100 Training:  38%|████████▍             | 46/120 [02:00<02:24,  1.95s/it, train_loss=0.113]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 41 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 42 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 43 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 44 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 45 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 46 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  42%|█████████▏            | 50/120 [02:06<01:43,  1.48s/it, train_loss=0.056]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 47 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 48 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 49 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 50 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  47%|██████████▎           | 56/120 [02:18<01:33,  1.46s/it, train_loss=0.184]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 51 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 52 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 53 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 54 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 55 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 56 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  49%|██████████▊           | 59/120 [02:27<02:44,  2.69s/it, train_loss=0.291]\n",
            "Validation after 60 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 57 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 58 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 59 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:   0%|                          | 0/10 [00:04<?, ?it/s, val_loss=0.0402]\u001b[A\n",
            "Validation after 60 batches:  10%|█▊                | 1/10 [00:04<00:41,  4.66s/it, val_loss=0.0402]\u001b[A\n",
            "Validation after 60 batches:  10%|█▉                 | 1/10 [00:04<00:41,  4.66s/it, val_loss=0.144]\u001b[A\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:04<00:15,  1.99s/it, val_loss=0.144]\u001b[A\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:08<00:15,  1.99s/it, val_loss=0.108]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▋             | 3/10 [00:08<00:18,  2.71s/it, val_loss=0.108]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▍            | 3/10 [00:08<00:18,  2.71s/it, val_loss=0.0143]\u001b[A\n",
            "Validation after 60 batches:  40%|███████▏          | 4/10 [00:08<00:10,  1.80s/it, val_loss=0.0143]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:  40%|███████▏          | 4/10 [00:13<00:10,  1.80s/it, val_loss=0.0395]\u001b[A\n",
            "Validation after 60 batches:  50%|█████████         | 5/10 [00:13<00:14,  2.90s/it, val_loss=0.0395]\u001b[A\n",
            "Validation after 60 batches:  50%|█████████         | 5/10 [00:14<00:14,  2.90s/it, val_loss=0.0127]\u001b[A\n",
            "Validation after 60 batches:  60%|██████████▊       | 6/10 [00:14<00:08,  2.24s/it, val_loss=0.0127]\u001b[A\n",
            "Validation after 60 batches:  60%|██████████▊       | 6/10 [00:16<00:08,  2.24s/it, val_loss=0.0824]\u001b[A\n",
            "Validation after 60 batches:  70%|████████████▌     | 7/10 [00:16<00:06,  2.15s/it, val_loss=0.0824]\u001b[A\n",
            "Validation after 60 batches:  70%|████████████▌     | 7/10 [00:16<00:06,  2.15s/it, val_loss=0.0986]\u001b[A\n",
            "Validation after 60 batches:  80%|██████████████▍   | 8/10 [00:16<00:03,  1.60s/it, val_loss=0.0986]\u001b[A\n",
            "Validation after 60 batches:  80%|███████████████▏   | 8/10 [00:18<00:03,  1.60s/it, val_loss=0.329]\u001b[A\n",
            "Validation after 60 batches:  90%|█████████████████  | 9/10 [00:18<00:01,  1.60s/it, val_loss=0.329]\u001b[A\n",
            "Validation after 60 batches:  90%|█████████████████  | 9/10 [00:18<00:01,  1.60s/it, val_loss=0.255]\u001b[A\n",
            "Validation after 60 batches: 100%|██████████████████| 10/10 [00:18<00:00,  1.89s/it, val_loss=0.255]\n",
            "Epoch 3/100 Training:  50%|███████████           | 60/120 [02:46<07:38,  7.65s/it, train_loss=0.291]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 60/120 batches: Val Loss: 0.0281  Val Acc: 0.9500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100 Training:  53%|███████████▋          | 64/120 [02:47<01:53,  2.03s/it, train_loss=0.178]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 61 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 62 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 63 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 64 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  58%|████████████▎        | 70/120 [02:59<01:37,  1.96s/it, train_loss=0.0999]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 65 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 66 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 67 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 68 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 69 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 70 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  62%|█████████████▊        | 75/120 [03:08<01:18,  1.75s/it, train_loss=0.249]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 71 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 72 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 73 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 74 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 75 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  66%|██████████████▍       | 79/120 [03:20<01:11,  1.74s/it, train_loss=0.111]\n",
            "Validation after 80 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 76 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 77 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 78 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 79 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 80 batches:   0%|                         | 0/10 [00:05<?, ?it/s, val_loss=0.00665]\u001b[A\n",
            "Validation after 80 batches:  10%|█▋               | 1/10 [00:05<00:51,  5.74s/it, val_loss=0.00665]\u001b[A\n",
            "Validation after 80 batches:  10%|█▉                 | 1/10 [00:05<00:51,  5.74s/it, val_loss=0.141]\u001b[A\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:05<00:19,  2.46s/it, val_loss=0.141]\u001b[A\n",
            "Validation after 80 batches:  20%|███▌              | 2/10 [00:09<00:19,  2.46s/it, val_loss=0.0847]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▍            | 3/10 [00:09<00:20,  2.91s/it, val_loss=0.0847]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▍            | 3/10 [00:09<00:20,  2.91s/it, val_loss=0.0138]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 80 batches:  30%|█████▋             | 3/10 [00:12<00:20,  2.91s/it, val_loss=0.035]\u001b[A\n",
            "Validation after 80 batches:  50%|█████████▌         | 5/10 [00:12<00:10,  2.13s/it, val_loss=0.035]\u001b[A\n",
            "Validation after 80 batches:  50%|████████▌        | 5/10 [00:12<00:10,  2.13s/it, val_loss=0.00762]\u001b[A\n",
            "Validation after 80 batches:  60%|██████████▏      | 6/10 [00:12<00:06,  1.55s/it, val_loss=0.00762]\u001b[A\n",
            "Validation after 80 batches:  60%|██████████▊       | 6/10 [00:14<00:06,  1.55s/it, val_loss=0.0928]\u001b[A\n",
            "Validation after 80 batches:  70%|████████████▌     | 7/10 [00:14<00:04,  1.65s/it, val_loss=0.0928]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:14<00:04,  1.65s/it, val_loss=0.128]\u001b[A\n",
            "Validation after 80 batches:  80%|███████████████▏   | 8/10 [00:14<00:02,  1.19s/it, val_loss=0.128]\u001b[A\n",
            "Validation after 80 batches:  80%|███████████████▏   | 8/10 [00:16<00:02,  1.19s/it, val_loss=0.347]\u001b[A\n",
            "Validation after 80 batches:  90%|█████████████████  | 9/10 [00:16<00:01,  1.35s/it, val_loss=0.347]\u001b[A\n",
            "Validation after 80 batches: 100%|███████████████████| 10/10 [00:16<00:00,  1.64s/it, val_loss=0.26]\n",
            "Epoch 3/100 Training:  67%|██████████████▋       | 80/120 [03:36<04:41,  7.05s/it, train_loss=0.111]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 80/120 batches: Val Loss: 0.0279  Val Acc: 0.9437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100 Training:  70%|████████████████       | 84/120 [03:37<01:08,  1.89s/it, train_loss=0.22]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 81 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 82 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 83 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 84 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  75%|████████████████▌     | 90/120 [03:50<00:43,  1.46s/it, train_loss=0.165]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 85 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 86 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 87 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 88 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 89 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 90 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  78%|██████████████████     | 94/120 [03:59<00:50,  1.96s/it, train_loss=0.14]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 91 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 92 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 93 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 94 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  82%|██████████████████▏   | 99/120 [04:10<00:51,  2.43s/it, train_loss=0.219]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 95 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 96 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 97 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 98 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 99 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  82%|██████████████████▏   | 99/120 [04:10<00:51,  2.43s/it, train_loss=0.183]\n",
            "Validation after 100 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 100 batches:   0%|                         | 0/10 [00:05<?, ?it/s, val_loss=0.0909]\u001b[A\n",
            "Validation after 100 batches:  10%|█▋               | 1/10 [00:05<00:45,  5.09s/it, val_loss=0.0909]\u001b[A\n",
            "Validation after 100 batches:  10%|█▊                | 1/10 [00:05<00:45,  5.09s/it, val_loss=0.181]\u001b[A\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:05<00:17,  2.17s/it, val_loss=0.181]\u001b[A\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:08<00:17,  2.17s/it, val_loss=0.136]\u001b[A\n",
            "Validation after 100 batches:  30%|█████▍            | 3/10 [00:08<00:20,  2.90s/it, val_loss=0.136]\u001b[A\n",
            "Validation after 100 batches:  30%|█████            | 3/10 [00:09<00:20,  2.90s/it, val_loss=0.0913]\u001b[A\n",
            "Validation after 100 batches:  40%|██████▊          | 4/10 [00:09<00:10,  1.81s/it, val_loss=0.0913]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 100 batches:  40%|███████▏          | 4/10 [00:12<00:10,  1.81s/it, val_loss=0.146]\u001b[A\n",
            "Validation after 100 batches:  50%|█████████         | 5/10 [00:12<00:11,  2.23s/it, val_loss=0.146]\u001b[A\n",
            "Validation after 100 batches:  50%|████████▌        | 5/10 [00:12<00:11,  2.23s/it, val_loss=0.0695]\u001b[A\n",
            "Validation after 100 batches:  60%|██████████▏      | 6/10 [00:12<00:06,  1.55s/it, val_loss=0.0695]\u001b[A\n",
            "Validation after 100 batches:  60%|██████████▊       | 6/10 [00:15<00:06,  1.55s/it, val_loss=0.104]\u001b[A\n",
            "Validation after 100 batches:  70%|████████████▌     | 7/10 [00:15<00:06,  2.22s/it, val_loss=0.104]\u001b[A\n",
            "Validation after 100 batches:  70%|████████████▌     | 7/10 [00:16<00:06,  2.22s/it, val_loss=0.174]\u001b[A\n",
            "Validation after 100 batches:  80%|██████████████▍   | 8/10 [00:16<00:03,  1.55s/it, val_loss=0.174]\u001b[A\n",
            "Validation after 100 batches:  80%|██████████████▍   | 8/10 [00:18<00:03,  1.55s/it, val_loss=0.204]\u001b[A\n",
            "Validation after 100 batches:  90%|████████████████▏ | 9/10 [00:18<00:01,  1.70s/it, val_loss=0.204]\u001b[A\n",
            "Validation after 100 batches: 100%|█████████████████| 10/10 [00:18<00:00,  1.82s/it, val_loss=0.275]\n",
            "Epoch 3/100 Training:  83%|█████████████████▌   | 100/120 [04:28<02:24,  7.25s/it, train_loss=0.183]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 100/120 batches: Val Loss: 0.0368  Val Acc: 0.9500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100 Training:  87%|█████████████████▎  | 104/120 [04:29<00:30,  1.93s/it, train_loss=0.0958]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 101 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 102 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 103 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 104 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  91%|███████████████████  | 109/120 [04:39<00:22,  2.00s/it, train_loss=0.202]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 105 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 106 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 107 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 108 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 109 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  96%|███████████████████▏| 115/120 [04:49<00:07,  1.44s/it, train_loss=0.0708]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 110 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 111 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 112 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 113 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 114 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 115 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Training:  99%|████████████████████▊| 119/120 [04:58<00:01,  1.89s/it, train_loss=0.185]\n",
            "Validation after 120 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 116 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 117 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 118 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 119 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 120 batches:   0%|                         | 0/10 [00:02<?, ?it/s, val_loss=0.0954]\u001b[A\n",
            "Validation after 120 batches:  10%|█▋               | 1/10 [00:02<00:21,  2.35s/it, val_loss=0.0954]\u001b[A\n",
            "Validation after 120 batches:  10%|█▊                | 1/10 [00:02<00:21,  2.35s/it, val_loss=0.321]\u001b[A\n",
            "Validation after 120 batches:  20%|███▌              | 2/10 [00:02<00:08,  1.03s/it, val_loss=0.321]\u001b[A\n",
            "Validation after 120 batches:  20%|███▌              | 2/10 [00:04<00:08,  1.03s/it, val_loss=0.215]\u001b[A\n",
            "Validation after 120 batches:  30%|█████▍            | 3/10 [00:04<00:09,  1.38s/it, val_loss=0.215]\u001b[A\n",
            "Validation after 120 batches:  30%|█████            | 3/10 [00:04<00:09,  1.38s/it, val_loss=0.0409]\u001b[A\n",
            "Validation after 120 batches:  40%|██████▊          | 4/10 [00:04<00:05,  1.14it/s, val_loss=0.0409]\u001b[A\n",
            "Validation after 120 batches:  40%|███████▏          | 4/10 [00:06<00:05,  1.14it/s, val_loss=0.163]\u001b[A\n",
            "Validation after 120 batches:  50%|█████████         | 5/10 [00:06<00:06,  1.25s/it, val_loss=0.163]\u001b[A\n",
            "Validation after 120 batches:  50%|████████▌        | 5/10 [00:06<00:06,  1.25s/it, val_loss=0.0157]\u001b[A\n",
            "Validation after 120 batches:  60%|██████████▏      | 6/10 [00:06<00:03,  1.08it/s, val_loss=0.0157]\u001b[A\n",
            "Validation after 120 batches:  60%|██████████▊       | 6/10 [00:09<00:03,  1.08it/s, val_loss=0.131]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:09<00:04,  1.49s/it, val_loss=0.131]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:09<00:04,  1.49s/it, val_loss=0.129]\u001b[A\n",
            "Validation after 120 batches:  80%|██████████████▍   | 8/10 [00:09<00:02,  1.24s/it, val_loss=0.129]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 120 batches:  80%|██████████████▍   | 8/10 [00:12<00:02,  1.24s/it, val_loss=0.167]\u001b[A\n",
            "Validation after 120 batches:  90%|████████████████▏ | 9/10 [00:12<00:01,  1.62s/it, val_loss=0.167]\u001b[A\n",
            "Validation after 120 batches:  90%|████████████████▏ | 9/10 [00:12<00:01,  1.62s/it, val_loss=0.409]\u001b[A\n",
            "Validation after 120 batches: 100%|█████████████████| 10/10 [00:12<00:00,  1.26s/it, val_loss=0.409]\n",
            "Epoch 3/100 Training: 100%|█████████████████████| 120/120 [05:11<00:00,  2.60s/it, train_loss=0.185]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 120/120 batches: Val Loss: 0.0422  Val Acc: 0.9125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100 Validation:  18%|████▏                   | 7/40 [00:08<00:37,  1.14s/it, val_loss=0.129]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 200. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/100 Validation: 100%|███████████████████████| 40/40 [01:17<00:00,  1.94s/it, val_loss=0.398]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/100] Train Loss: 0.2101  Train Acc: 0.9042 Val Loss: 0.2475  Val Acc: 0.8891\n",
            "✅ Best model saved with Val Acc: 0.8891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100 Training:   0%|                                                 | 0/120 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:   3%|▊                      | 4/120 [00:08<03:34,  1.85s/it, train_loss=0.235]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:   8%|█▊                    | 10/120 [00:19<03:07,  1.71s/it, train_loss=0.176]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  12%|██▋                    | 14/120 [00:28<03:23,  1.92s/it, train_loss=0.11]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 11 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 12 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 13 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 14 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  15%|███▎                  | 18/120 [00:38<03:36,  2.13s/it, train_loss=0.359]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 15 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 16 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 17 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 18 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  16%|███▍                  | 19/120 [00:43<04:47,  2.85s/it, train_loss=0.413]\n",
            "Validation after 20 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 20 batches:   0%|                           | 0/10 [00:04<?, ?it/s, val_loss=0.224]\u001b[A\n",
            "Validation after 20 batches:  10%|█▉                 | 1/10 [00:04<00:44,  4.93s/it, val_loss=0.224]\u001b[A\n",
            "Validation after 20 batches:  10%|█▉                 | 1/10 [00:05<00:44,  4.93s/it, val_loss=0.443]\u001b[A\n",
            "Validation after 20 batches:  20%|███▊               | 2/10 [00:05<00:16,  2.11s/it, val_loss=0.443]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 19 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:  20%|███▊               | 2/10 [00:09<00:16,  2.11s/it, val_loss=0.288]\u001b[A\n",
            "Validation after 20 batches:  30%|█████▋             | 3/10 [00:09<00:22,  3.28s/it, val_loss=0.288]\u001b[A\n",
            "Validation after 20 batches:  30%|█████▋             | 3/10 [00:09<00:22,  3.28s/it, val_loss=0.167]\u001b[A\n",
            "Validation after 20 batches:  40%|███████▌           | 4/10 [00:09<00:12,  2.05s/it, val_loss=0.167]\u001b[A\n",
            "Validation after 20 batches:  40%|███████▌           | 4/10 [00:12<00:12,  2.05s/it, val_loss=0.421]\u001b[A\n",
            "Validation after 20 batches:  50%|█████████▌         | 5/10 [00:12<00:11,  2.31s/it, val_loss=0.421]\u001b[A\n",
            "Validation after 20 batches:  50%|█████████▌         | 5/10 [00:12<00:11,  2.31s/it, val_loss=0.118]\u001b[A\n",
            "Validation after 20 batches:  60%|███████████▍       | 6/10 [00:12<00:06,  1.56s/it, val_loss=0.118]\u001b[A\n",
            "Validation after 20 batches:  60%|███████████▍       | 6/10 [00:14<00:06,  1.56s/it, val_loss=0.265]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:14<00:05,  1.73s/it, val_loss=0.265]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:14<00:05,  1.73s/it, val_loss=0.135]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:16<00:05,  1.73s/it, val_loss=0.158]\u001b[A\n",
            "Validation after 20 batches:  90%|█████████████████  | 9/10 [00:16<00:01,  1.38s/it, val_loss=0.158]\u001b[A\n",
            "Validation after 20 batches: 100%|██████████████████| 10/10 [00:16<00:00,  1.70s/it, val_loss=0.627]\n",
            "Epoch 4/100 Training:  17%|███▋                  | 20/120 [01:00<11:57,  7.18s/it, train_loss=0.413]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 20/120 batches: Val Loss: 0.0711  Val Acc: 0.8500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100 Training:  20%|████▍                 | 24/120 [01:01<03:04,  1.92s/it, train_loss=0.229]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 21 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 22 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 23 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 24 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  23%|████▉                | 28/120 [01:09<02:53,  1.88s/it, train_loss=0.0857]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 25 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 26 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 27 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 28 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  28%|██████                | 33/120 [01:21<03:22,  2.33s/it, train_loss=0.418]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 29 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 30 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 31 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 32 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 33 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  32%|██████▉               | 38/120 [01:29<02:17,  1.67s/it, train_loss=0.202]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 34 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 35 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 36 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 37 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 38 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  32%|██████▊              | 39/120 [01:33<03:11,  2.37s/it, train_loss=0.0435]\n",
            "Validation after 40 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 40 batches:   0%|                          | 0/10 [00:06<?, ?it/s, val_loss=0.0671]\u001b[A\n",
            "Validation after 40 batches:  10%|█▊                | 1/10 [00:06<00:57,  6.43s/it, val_loss=0.0671]\u001b[A\n",
            "Validation after 40 batches:  10%|█▉                 | 1/10 [00:06<00:57,  6.43s/it, val_loss=0.204]\u001b[A\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:06<00:21,  2.72s/it, val_loss=0.204]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 39 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:09<00:21,  2.72s/it, val_loss=0.113]\u001b[A\n",
            "Validation after 40 batches:  30%|█████▋             | 3/10 [00:09<00:20,  2.87s/it, val_loss=0.113]\u001b[A\n",
            "Validation after 40 batches:  30%|█████▍            | 3/10 [00:09<00:20,  2.87s/it, val_loss=0.0332]\u001b[A\n",
            "Validation after 40 batches:  40%|███████▏          | 4/10 [00:09<00:10,  1.78s/it, val_loss=0.0332]\u001b[A\n",
            "Validation after 40 batches:  40%|███████▏          | 4/10 [00:12<00:10,  1.78s/it, val_loss=0.0979]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████         | 5/10 [00:12<00:11,  2.31s/it, val_loss=0.0979]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████         | 5/10 [00:13<00:11,  2.31s/it, val_loss=0.0465]\u001b[A\n",
            "Validation after 40 batches:  60%|██████████▊       | 6/10 [00:13<00:06,  1.57s/it, val_loss=0.0465]\u001b[A\n",
            "Validation after 40 batches:  60%|████████████        | 6/10 [00:16<00:06,  1.57s/it, val_loss=0.11]\u001b[A\n",
            "Validation after 40 batches:  70%|██████████████      | 7/10 [00:16<00:06,  2.03s/it, val_loss=0.11]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:16<00:06,  2.03s/it, val_loss=0.165]\u001b[A\n",
            "Validation after 40 batches:  80%|███████████████▏   | 8/10 [00:16<00:02,  1.42s/it, val_loss=0.165]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:  80%|███████████████▏   | 8/10 [00:19<00:02,  1.42s/it, val_loss=0.283]\u001b[A\n",
            "Validation after 40 batches:  90%|█████████████████  | 9/10 [00:19<00:01,  1.87s/it, val_loss=0.283]\u001b[A\n",
            "Validation after 40 batches: 100%|██████████████████| 10/10 [00:19<00:00,  1.92s/it, val_loss=0.323]\n",
            "Epoch 4/100 Training:  33%|███████              | 40/120 [01:52<10:00,  7.51s/it, train_loss=0.0435]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 40/120 batches: Val Loss: 0.0360  Val Acc: 0.9437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100 Training:  40%|████████▊             | 48/120 [02:00<01:51,  1.55s/it, train_loss=0.213]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 41 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 42 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 43 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 44 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 45 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 46 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 47 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 48 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  43%|█████████            | 52/120 [02:09<02:08,  1.89s/it, train_loss=0.0207]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 49 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 50 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 51 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 52 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  48%|█████████▉           | 57/120 [02:20<02:22,  2.26s/it, train_loss=0.0605]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 53 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 54 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 55 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 56 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 57 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  49%|██████████▊           | 59/120 [02:25<01:47,  1.77s/it, train_loss=0.122]\n",
            "Validation after 60 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 60 batches:   0%|                          | 0/10 [00:04<?, ?it/s, val_loss=0.0768]\u001b[A\n",
            "Validation after 60 batches:  10%|█▊                | 1/10 [00:04<00:39,  4.40s/it, val_loss=0.0768]\u001b[A\n",
            "Validation after 60 batches:  10%|█▉                 | 1/10 [00:04<00:39,  4.40s/it, val_loss=0.255]\u001b[A\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:04<00:15,  1.89s/it, val_loss=0.255]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 58 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 59 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:08<00:15,  1.89s/it, val_loss=0.194]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▋             | 3/10 [00:08<00:21,  3.05s/it, val_loss=0.194]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▍            | 3/10 [00:09<00:21,  3.05s/it, val_loss=0.0275]\u001b[A\n",
            "Validation after 60 batches:  40%|███████▏          | 4/10 [00:09<00:11,  1.90s/it, val_loss=0.0275]\u001b[A\n",
            "Validation after 60 batches:  40%|███████▏          | 4/10 [00:12<00:11,  1.90s/it, val_loss=0.0976]\u001b[A\n",
            "Validation after 60 batches:  50%|█████████         | 5/10 [00:12<00:12,  2.43s/it, val_loss=0.0976]\u001b[A\n",
            "Validation after 60 batches:  50%|█████████         | 5/10 [00:12<00:12,  2.43s/it, val_loss=0.0213]\u001b[A\n",
            "Validation after 60 batches:  60%|██████████▊       | 6/10 [00:12<00:06,  1.64s/it, val_loss=0.0213]\u001b[A\n",
            "Validation after 60 batches:  60%|███████████▍       | 6/10 [00:14<00:06,  1.64s/it, val_loss=0.169]\u001b[A\n",
            "Validation after 60 batches:  70%|█████████████▎     | 7/10 [00:14<00:05,  1.77s/it, val_loss=0.169]\u001b[A\n",
            "Validation after 60 batches:  70%|█████████████▎     | 7/10 [00:14<00:05,  1.77s/it, val_loss=0.095]\u001b[A\n",
            "Validation after 60 batches:  80%|███████████████▏   | 8/10 [00:14<00:02,  1.24s/it, val_loss=0.095]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:  80%|███████████████▏   | 8/10 [00:16<00:02,  1.24s/it, val_loss=0.321]\u001b[A\n",
            "Validation after 60 batches:  90%|█████████████████  | 9/10 [00:16<00:01,  1.43s/it, val_loss=0.321]\u001b[A\n",
            "Validation after 60 batches: 100%|██████████████████| 10/10 [00:16<00:00,  1.67s/it, val_loss=0.362]\n",
            "Epoch 4/100 Training:  50%|███████████           | 60/120 [02:42<07:01,  7.03s/it, train_loss=0.122]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 60/120 batches: Val Loss: 0.0405  Val Acc: 0.9313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100 Training:  55%|████████████          | 66/120 [02:46<01:26,  1.60s/it, train_loss=0.197]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 61 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 62 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 63 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 64 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 65 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 66 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  60%|████████████▌        | 72/120 [03:00<01:23,  1.73s/it, train_loss=0.0759]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 67 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 68 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 69 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 70 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 71 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 72 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  63%|█████████████▉        | 76/120 [03:10<01:23,  1.90s/it, train_loss=0.198]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 73 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 74 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 75 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 76 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  66%|██████████████▍       | 79/120 [03:19<01:45,  2.57s/it, train_loss=0.123]\n",
            "Validation after 80 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 77 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 78 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 79 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 80 batches:   0%|                          | 0/10 [00:05<?, ?it/s, val_loss=0.0944]\u001b[A\n",
            "Validation after 80 batches:  10%|█▊                | 1/10 [00:05<00:50,  5.59s/it, val_loss=0.0944]\u001b[A\n",
            "Validation after 80 batches:  10%|█▉                 | 1/10 [00:05<00:50,  5.59s/it, val_loss=0.441]\u001b[A\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:05<00:18,  2.37s/it, val_loss=0.441]\u001b[A\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:09<00:18,  2.37s/it, val_loss=0.282]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▋             | 3/10 [00:09<00:20,  2.98s/it, val_loss=0.282]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▋             | 3/10 [00:09<00:20,  2.98s/it, val_loss=0.191]\u001b[A\n",
            "Validation after 80 batches:  40%|███████▌           | 4/10 [00:09<00:11,  1.86s/it, val_loss=0.191]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 80 batches:  40%|███████▏          | 4/10 [00:12<00:11,  1.86s/it, val_loss=0.0993]\u001b[A\n",
            "Validation after 80 batches:  50%|█████████         | 5/10 [00:12<00:10,  2.18s/it, val_loss=0.0993]\u001b[A\n",
            "Validation after 80 batches:  50%|████████▌        | 5/10 [00:13<00:10,  2.18s/it, val_loss=0.00784]\u001b[A\n",
            "Validation after 80 batches:  60%|██████████▏      | 6/10 [00:13<00:06,  1.70s/it, val_loss=0.00784]\u001b[A\n",
            "Validation after 80 batches:  60%|███████████▍       | 6/10 [00:16<00:06,  1.70s/it, val_loss=0.208]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:16<00:06,  2.15s/it, val_loss=0.208]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:16<00:06,  2.15s/it, val_loss=0.126]\u001b[A\n",
            "Validation after 80 batches:  80%|███████████████▏   | 8/10 [00:16<00:03,  1.59s/it, val_loss=0.126]\u001b[A\n",
            "Validation after 80 batches:  80%|███████████████▏   | 8/10 [00:18<00:03,  1.59s/it, val_loss=0.213]\u001b[A\n",
            "Validation after 80 batches:  90%|█████████████████  | 9/10 [00:18<00:01,  1.71s/it, val_loss=0.213]\u001b[A\n",
            "Validation after 80 batches:  90%|█████████████████  | 9/10 [00:18<00:01,  1.71s/it, val_loss=0.404]\u001b[A\n",
            "Validation after 80 batches: 100%|██████████████████| 10/10 [00:18<00:00,  1.87s/it, val_loss=0.404]\n",
            "Epoch 4/100 Training:  67%|██████████████▋       | 80/120 [03:37<05:00,  7.50s/it, train_loss=0.123]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 80/120 batches: Val Loss: 0.0517  Val Acc: 0.9062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100 Training:  71%|██████████████▉      | 85/120 [03:40<01:09,  1.98s/it, train_loss=0.0688]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 81 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 82 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 83 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 84 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  72%|███████████████▊      | 86/120 [03:41<00:51,  1.52s/it, train_loss=0.135]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 85 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  75%|████████████████▌     | 90/120 [03:49<00:54,  1.82s/it, train_loss=0.161]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 86 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 87 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 88 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 89 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 90 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  80%|████████████████▊    | 96/120 [04:00<00:42,  1.77s/it, train_loss=0.0797]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 91 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 92 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 93 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 94 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 95 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 96 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  82%|█████████████████▎   | 99/120 [04:08<00:36,  1.72s/it, train_loss=0.0805]\n",
            "Validation after 100 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 97 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 98 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 99 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 100 batches:   0%|                          | 0/10 [00:04<?, ?it/s, val_loss=0.155]\u001b[A\n",
            "Validation after 100 batches:  10%|█▊                | 1/10 [00:04<00:41,  4.60s/it, val_loss=0.155]\u001b[A\n",
            "Validation after 100 batches:  10%|█▊                | 1/10 [00:04<00:41,  4.60s/it, val_loss=0.287]\u001b[A\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:04<00:15,  1.99s/it, val_loss=0.287]\u001b[A\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:09<00:15,  1.99s/it, val_loss=0.212]\u001b[A\n",
            "Validation after 100 batches:  30%|█████▍            | 3/10 [00:09<00:21,  3.12s/it, val_loss=0.212]\u001b[A\n",
            "Validation after 100 batches:  30%|█████            | 3/10 [00:09<00:21,  3.12s/it, val_loss=0.0637]\u001b[A\n",
            "Validation after 100 batches:  40%|██████▊          | 4/10 [00:09<00:11,  1.96s/it, val_loss=0.0637]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 100 batches:  40%|███████▏          | 4/10 [00:13<00:11,  1.96s/it, val_loss=0.131]\u001b[A\n",
            "Validation after 100 batches:  50%|█████████         | 5/10 [00:13<00:13,  2.72s/it, val_loss=0.131]\u001b[A\n",
            "Validation after 100 batches:  50%|█████████         | 5/10 [00:13<00:13,  2.72s/it, val_loss=0.021]\u001b[A\n",
            "Validation after 100 batches:  60%|██████████▊       | 6/10 [00:13<00:07,  1.84s/it, val_loss=0.021]\u001b[A\n",
            "Validation after 100 batches:  60%|██████████▊       | 6/10 [00:15<00:07,  1.84s/it, val_loss=0.114]\u001b[A\n",
            "Validation after 100 batches:  70%|████████████▌     | 7/10 [00:15<00:05,  1.94s/it, val_loss=0.114]\u001b[A\n",
            "Validation after 100 batches:  70%|███████████▉     | 7/10 [00:15<00:05,  1.94s/it, val_loss=0.0994]\u001b[A\n",
            "Validation after 100 batches:  80%|█████████████▌   | 8/10 [00:15<00:02,  1.36s/it, val_loss=0.0994]\u001b[A\n",
            "Validation after 100 batches:  80%|██████████████▍   | 8/10 [00:17<00:02,  1.36s/it, val_loss=0.405]\u001b[A\n",
            "Validation after 100 batches:  90%|████████████████▏ | 9/10 [00:17<00:01,  1.53s/it, val_loss=0.405]\u001b[A\n",
            "Validation after 100 batches: 100%|█████████████████| 10/10 [00:17<00:00,  1.79s/it, val_loss=0.437]\n",
            "Epoch 4/100 Training:  83%|████████████████▋   | 100/120 [04:26<02:25,  7.29s/it, train_loss=0.0805]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 100/120 batches: Val Loss: 0.0481  Val Acc: 0.9125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100 Training:  88%|█████████████████▌  | 105/120 [04:29<00:27,  1.80s/it, train_loss=0.0393]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 101 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 102 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 103 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 104 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 105 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  92%|███████████████████▎ | 110/120 [04:39<00:17,  1.76s/it, train_loss=0.265]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 106 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 107 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 108 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 109 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 110 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  96%|████████████████████▏| 115/120 [04:50<00:11,  2.37s/it, train_loss=0.146]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 111 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 112 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 113 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 114 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 115 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Training:  99%|████████████████████▊| 119/120 [04:58<00:01,  1.80s/it, train_loss=0.147]\n",
            "Validation after 120 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 116 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 117 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 118 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 119 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 120 batches:   0%|                         | 0/10 [00:02<?, ?it/s, val_loss=0.0101]\u001b[A\n",
            "Validation after 120 batches:  10%|█▋               | 1/10 [00:02<00:25,  2.78s/it, val_loss=0.0101]\u001b[A\n",
            "Validation after 120 batches:  10%|█▊                | 1/10 [00:02<00:25,  2.78s/it, val_loss=0.154]\u001b[A\n",
            "Validation after 120 batches:  20%|███▌              | 2/10 [00:02<00:09,  1.21s/it, val_loss=0.154]\u001b[A\n",
            "Validation after 120 batches:  20%|███▍             | 2/10 [00:06<00:09,  1.21s/it, val_loss=0.0518]\u001b[A\n",
            "Validation after 120 batches:  30%|█████            | 3/10 [00:06<00:15,  2.19s/it, val_loss=0.0518]\u001b[A\n",
            "Validation after 120 batches:  30%|████▊           | 3/10 [00:06<00:15,  2.19s/it, val_loss=0.00443]\u001b[A\n",
            "Validation after 120 batches:  40%|██████▍         | 4/10 [00:06<00:08,  1.36s/it, val_loss=0.00443]\u001b[A\n",
            "Validation after 120 batches:  40%|███████▏          | 4/10 [00:08<00:08,  1.36s/it, val_loss=0.152]\u001b[A\n",
            "Validation after 120 batches:  50%|█████████         | 5/10 [00:08<00:08,  1.61s/it, val_loss=0.152]\u001b[A\n",
            "Validation after 120 batches:  50%|███████▌       | 5/10 [00:08<00:08,  1.61s/it, val_loss=0.000849]\u001b[A\n",
            "Validation after 120 batches:  50%|████████▌        | 5/10 [00:10<00:08,  1.61s/it, val_loss=0.0475]\u001b[A\n",
            "Validation after 120 batches:  70%|███████████▉     | 7/10 [00:10<00:04,  1.33s/it, val_loss=0.0475]\u001b[A\n",
            "Validation after 120 batches:  70%|███████████▉     | 7/10 [00:10<00:04,  1.33s/it, val_loss=0.0926]\u001b[A\n",
            "Validation after 120 batches:  80%|█████████████▌   | 8/10 [00:10<00:02,  1.01s/it, val_loss=0.0926]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 120 batches:  80%|██████████████▍   | 8/10 [00:12<00:02,  1.01s/it, val_loss=0.314]\u001b[A\n",
            "Validation after 120 batches:  90%|████████████████▏ | 9/10 [00:12<00:01,  1.27s/it, val_loss=0.314]\u001b[A\n",
            "Validation after 120 batches: 100%|█████████████████| 10/10 [00:12<00:00,  1.27s/it, val_loss=0.263]\n",
            "Epoch 4/100 Training: 100%|█████████████████████| 120/120 [05:11<00:00,  2.60s/it, train_loss=0.147]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 120/120 batches: Val Loss: 0.0272  Val Acc: 0.9563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100 Validation:  12%|██▋                  | 5/40 [00:08<01:02,  1.78s/it, val_loss=0.000849]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 240. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/100 Validation: 100%|███████████████████████| 40/40 [01:18<00:00,  1.96s/it, val_loss=0.545]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/100] Train Loss: 0.1691  Train Acc: 0.9318 Val Loss: 0.3644  Val Acc: 0.8875\n",
            "⚠️ No improvement in Val Acc for 1 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100 Training:   0%|                                                 | 0/120 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:   4%|▉                      | 5/120 [00:10<03:31,  1.84s/it, train_loss=0.232]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:   7%|█▌                     | 8/120 [00:18<04:21,  2.34s/it, train_loss=0.144]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  10%|██▍                     | 12/120 [00:26<03:22,  1.88s/it, train_loss=0.2]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 11 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 12 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  15%|███▏                 | 18/120 [00:39<02:49,  1.67s/it, train_loss=0.0864]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 13 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 14 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 15 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 16 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 17 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 18 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  16%|███▍                  | 19/120 [00:42<03:25,  2.03s/it, train_loss=0.276]\n",
            "Validation after 20 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 20 batches:   0%|                         | 0/10 [00:06<?, ?it/s, val_loss=0.00104]\u001b[A\n",
            "Validation after 20 batches:  10%|█▋               | 1/10 [00:06<00:59,  6.63s/it, val_loss=0.00104]\u001b[A\n",
            "Validation after 20 batches:  10%|█▉                 | 1/10 [00:06<00:59,  6.63s/it, val_loss=0.173]\u001b[A\n",
            "Validation after 20 batches:  20%|███▊               | 2/10 [00:06<00:22,  2.80s/it, val_loss=0.173]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 19 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:  20%|███▌              | 2/10 [00:09<00:22,  2.80s/it, val_loss=0.0417]\u001b[A\n",
            "Validation after 20 batches:  30%|█████▍            | 3/10 [00:09<00:19,  2.82s/it, val_loss=0.0417]\u001b[A\n",
            "Validation after 20 batches:  30%|█████            | 3/10 [00:09<00:19,  2.82s/it, val_loss=0.00458]\u001b[A\n",
            "Validation after 20 batches:  40%|██████▊          | 4/10 [00:09<00:10,  1.76s/it, val_loss=0.00458]\u001b[A\n",
            "Validation after 20 batches:  40%|███████▌           | 4/10 [00:12<00:10,  1.76s/it, val_loss=0.134]\u001b[A\n",
            "Validation after 20 batches:  50%|█████████▌         | 5/10 [00:12<00:10,  2.19s/it, val_loss=0.134]\u001b[A\n",
            "Validation after 20 batches:  50%|████████        | 5/10 [00:12<00:10,  2.19s/it, val_loss=0.000947]\u001b[A\n",
            "Validation after 20 batches:  60%|█████████▌      | 6/10 [00:12<00:06,  1.54s/it, val_loss=0.000947]\u001b[A\n",
            "Validation after 20 batches:  60%|███████████▍       | 6/10 [00:14<00:06,  1.54s/it, val_loss=0.046]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:14<00:04,  1.63s/it, val_loss=0.046]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:15<00:04,  1.63s/it, val_loss=0.116]\u001b[A\n",
            "Validation after 20 batches:  80%|███████████████▏   | 8/10 [00:15<00:02,  1.20s/it, val_loss=0.116]\u001b[A\n",
            "Validation after 20 batches:  80%|███████████████▏   | 8/10 [00:18<00:02,  1.20s/it, val_loss=0.281]\u001b[A\n",
            "Validation after 20 batches:  90%|█████████████████  | 9/10 [00:18<00:01,  1.75s/it, val_loss=0.281]\u001b[A\n",
            "Validation after 20 batches: 100%|██████████████████| 10/10 [00:18<00:00,  1.82s/it, val_loss=0.214]\n",
            "Epoch 5/100 Training:  17%|███▋                  | 20/120 [01:00<11:37,  6.97s/it, train_loss=0.276]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 20/120 batches: Val Loss: 0.0253  Val Acc: 0.9563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100 Training:  18%|████▏                  | 22/120 [01:01<05:48,  3.55s/it, train_loss=0.19]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 21 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 22 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  23%|█████▏                | 28/120 [01:10<03:01,  1.97s/it, train_loss=0.409]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 23 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 24 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 25 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 26 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 27 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 28 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  27%|██████▍                 | 32/120 [01:21<02:56,  2.00s/it, train_loss=0.2]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 29 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 30 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 31 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 32 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  30%|██████▎              | 36/120 [01:27<02:14,  1.60s/it, train_loss=0.0842]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 33 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 34 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 35 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 36 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  32%|██████▊              | 39/120 [01:35<02:58,  2.20s/it, train_loss=0.0925]\n",
            "Validation after 40 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 40 batches:   0%|                           | 0/10 [00:04<?, ?it/s, val_loss=0.457]\u001b[A\n",
            "Validation after 40 batches:  10%|█▉                 | 1/10 [00:04<00:40,  4.49s/it, val_loss=0.457]\u001b[A\n",
            "Validation after 40 batches:  10%|█▉                 | 1/10 [00:04<00:40,  4.49s/it, val_loss=0.848]\u001b[A\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:04<00:15,  1.94s/it, val_loss=0.848]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 37 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 38 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 39 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:10<00:15,  1.94s/it, val_loss=0.624]\u001b[A\n",
            "Validation after 40 batches:  30%|█████▋             | 3/10 [00:10<00:25,  3.58s/it, val_loss=0.624]\u001b[A\n",
            "Validation after 40 batches:  30%|█████▋             | 3/10 [00:10<00:25,  3.58s/it, val_loss=0.373]\u001b[A\n",
            "Validation after 40 batches:  40%|███████▌           | 4/10 [00:10<00:13,  2.24s/it, val_loss=0.373]\u001b[A\n",
            "Validation after 40 batches:  40%|███████▌           | 4/10 [00:13<00:13,  2.24s/it, val_loss=0.635]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████▌         | 5/10 [00:13<00:13,  2.72s/it, val_loss=0.635]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████▌         | 5/10 [00:14<00:13,  2.72s/it, val_loss=0.155]\u001b[A\n",
            "Validation after 40 batches:  60%|███████████▍       | 6/10 [00:14<00:07,  1.84s/it, val_loss=0.155]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:  60%|███████████▍       | 6/10 [00:16<00:07,  1.84s/it, val_loss=0.491]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:16<00:05,  1.97s/it, val_loss=0.491]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:16<00:05,  1.97s/it, val_loss=0.233]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:18<00:05,  1.97s/it, val_loss=0.231]\u001b[A\n",
            "Validation after 40 batches:  90%|█████████████████  | 9/10 [00:18<00:01,  1.49s/it, val_loss=0.231]\u001b[A\n",
            "Validation after 40 batches: 100%|███████████████████| 10/10 [00:18<00:00,  1.84s/it, val_loss=1.04]\n",
            "Epoch 5/100 Training:  33%|███████              | 40/120 [01:54<09:31,  7.14s/it, train_loss=0.0925]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 40/120 batches: Val Loss: 0.1272  Val Acc: 0.8063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100 Training:  38%|████████▍             | 46/120 [02:00<02:42,  2.19s/it, train_loss=0.175]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 41 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 42 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 43 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 44 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 45 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 46 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  43%|█████████▌            | 52/120 [02:09<01:40,  1.47s/it, train_loss=0.115]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 47 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 48 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 49 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 50 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 51 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 52 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  48%|█████████▉           | 57/120 [02:19<01:42,  1.63s/it, train_loss=0.0627]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 53 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 54 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 55 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 56 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 57 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  49%|██████████▊           | 59/120 [02:25<01:37,  1.60s/it, train_loss=0.158]\n",
            "Validation after 60 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 58 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 59 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:   0%|                            | 0/10 [00:06<?, ?it/s, val_loss=0.26]\u001b[A\n",
            "Validation after 60 batches:  10%|██                  | 1/10 [00:06<00:59,  6.56s/it, val_loss=0.26]\u001b[A\n",
            "Validation after 60 batches:  10%|█▉                 | 1/10 [00:06<00:59,  6.56s/it, val_loss=0.666]\u001b[A\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:06<00:22,  2.79s/it, val_loss=0.666]\u001b[A\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:10<00:22,  2.79s/it, val_loss=0.507]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▋             | 3/10 [00:10<00:22,  3.19s/it, val_loss=0.507]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▍            | 3/10 [00:10<00:22,  3.19s/it, val_loss=0.0974]\u001b[A\n",
            "Validation after 60 batches:  40%|███████▏          | 4/10 [00:10<00:11,  1.98s/it, val_loss=0.0974]\u001b[A\n",
            "Validation after 60 batches:  40%|███████▌           | 4/10 [00:13<00:11,  1.98s/it, val_loss=0.255]\u001b[A\n",
            "Validation after 60 batches:  50%|█████████▌         | 5/10 [00:13<00:11,  2.36s/it, val_loss=0.255]\u001b[A\n",
            "Validation after 60 batches:  50%|█████████▌         | 5/10 [00:13<00:11,  2.36s/it, val_loss=0.018]\u001b[A\n",
            "Validation after 60 batches:  60%|███████████▍       | 6/10 [00:13<00:06,  1.61s/it, val_loss=0.018]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:  60%|████████████        | 6/10 [00:17<00:06,  1.61s/it, val_loss=0.32]\u001b[A\n",
            "Validation after 60 batches:  70%|██████████████      | 7/10 [00:17<00:06,  2.32s/it, val_loss=0.32]\u001b[A\n",
            "Validation after 60 batches:  70%|████████████▌     | 7/10 [00:17<00:06,  2.32s/it, val_loss=0.0945]\u001b[A\n",
            "Validation after 60 batches:  80%|██████████████▍   | 8/10 [00:17<00:03,  1.62s/it, val_loss=0.0945]\u001b[A\n",
            "Validation after 60 batches:  80%|███████████████▏   | 8/10 [00:20<00:03,  1.62s/it, val_loss=0.162]\u001b[A\n",
            "Validation after 60 batches:  90%|█████████████████  | 9/10 [00:20<00:02,  2.02s/it, val_loss=0.162]\u001b[A\n",
            "Validation after 60 batches: 100%|██████████████████| 10/10 [00:20<00:00,  2.06s/it, val_loss=0.791]\n",
            "Epoch 5/100 Training:  50%|███████████           | 60/120 [02:46<08:08,  8.15s/it, train_loss=0.158]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 60/120 batches: Val Loss: 0.0792  Val Acc: 0.8875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100 Training:  55%|███████████▌         | 66/120 [02:50<01:30,  1.68s/it, train_loss=0.0427]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 61 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 62 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 63 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 64 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 65 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 66 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  58%|████████████▎        | 70/120 [02:57<01:19,  1.59s/it, train_loss=0.0728]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 67 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 68 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 69 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 70 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  63%|█████████████▎       | 76/120 [03:09<01:16,  1.73s/it, train_loss=0.0873]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 71 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 72 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 73 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 74 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 75 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 76 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  66%|█████████████▊       | 79/120 [03:19<01:45,  2.56s/it, train_loss=0.0615]\n",
            "Validation after 80 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 77 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 78 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 79 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 80 batches:   0%|                           | 0/10 [00:04<?, ?it/s, val_loss=0.099]\u001b[A\n",
            "Validation after 80 batches:  10%|█▉                 | 1/10 [00:04<00:41,  4.59s/it, val_loss=0.099]\u001b[A\n",
            "Validation after 80 batches:  10%|█▉                 | 1/10 [00:04<00:41,  4.59s/it, val_loss=0.262]\u001b[A\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:04<00:15,  1.97s/it, val_loss=0.262]\u001b[A\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:09<00:15,  1.97s/it, val_loss=0.206]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▋             | 3/10 [00:09<00:24,  3.43s/it, val_loss=0.206]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▍            | 3/10 [00:10<00:24,  3.43s/it, val_loss=0.0178]\u001b[A\n",
            "Validation after 80 batches:  40%|███████▏          | 4/10 [00:10<00:12,  2.13s/it, val_loss=0.0178]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 80 batches:  40%|███████▏          | 4/10 [00:13<00:12,  2.13s/it, val_loss=0.0833]\u001b[A\n",
            "Validation after 80 batches:  50%|█████████         | 5/10 [00:13<00:13,  2.72s/it, val_loss=0.0833]\u001b[A\n",
            "Validation after 80 batches:  50%|█████████         | 5/10 [00:13<00:13,  2.72s/it, val_loss=0.0269]\u001b[A\n",
            "Validation after 80 batches:  60%|██████████▊       | 6/10 [00:13<00:07,  1.83s/it, val_loss=0.0269]\u001b[A\n",
            "Validation after 80 batches:  60%|███████████▍       | 6/10 [00:16<00:07,  1.83s/it, val_loss=0.195]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:16<00:05,  1.94s/it, val_loss=0.195]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:16<00:05,  1.94s/it, val_loss=0.103]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:17<00:05,  1.94s/it, val_loss=0.412]\u001b[A\n",
            "Validation after 80 batches:  90%|█████████████████  | 9/10 [00:17<00:01,  1.45s/it, val_loss=0.412]\u001b[A\n",
            "Validation after 80 batches: 100%|██████████████████| 10/10 [00:18<00:00,  1.81s/it, val_loss=0.485]\n",
            "Epoch 5/100 Training:  67%|██████████████       | 80/120 [03:37<04:51,  7.29s/it, train_loss=0.0615]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 80/120 batches: Val Loss: 0.0473  Val Acc: 0.9062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100 Training:  71%|██████████████▉      | 85/120 [03:40<01:11,  2.05s/it, train_loss=0.0765]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 81 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 82 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 83 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 84 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 85 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  75%|███████████████▊     | 90/120 [03:49<00:51,  1.71s/it, train_loss=0.0325]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 86 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 87 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 88 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 89 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 90 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  79%|████████████████▋    | 95/120 [04:00<00:56,  2.24s/it, train_loss=0.0271]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 91 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 92 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 93 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 94 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 95 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  82%|██████████████████▏   | 99/120 [04:09<00:37,  1.78s/it, train_loss=0.023]\n",
            "Validation after 100 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 96 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 97 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 98 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 99 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 100 batches:   0%|                        | 0/10 [00:06<?, ?it/s, val_loss=0.00288]\u001b[A\n",
            "Validation after 100 batches:  10%|█▌              | 1/10 [00:06<00:59,  6.62s/it, val_loss=0.00288]\u001b[A\n",
            "Validation after 100 batches:  10%|█▊                | 1/10 [00:06<00:59,  6.62s/it, val_loss=0.196]\u001b[A\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:06<00:22,  2.81s/it, val_loss=0.196]\u001b[A\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:10<00:22,  2.81s/it, val_loss=0.161]\u001b[A\n",
            "Validation after 100 batches:  30%|█████▍            | 3/10 [00:10<00:24,  3.43s/it, val_loss=0.161]\u001b[A\n",
            "Validation after 100 batches:  30%|█████            | 3/10 [00:11<00:24,  3.43s/it, val_loss=0.0749]\u001b[A\n",
            "Validation after 100 batches:  40%|██████▊          | 4/10 [00:11<00:12,  2.13s/it, val_loss=0.0749]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 100 batches:  40%|██████▍         | 4/10 [00:13<00:12,  2.13s/it, val_loss=0.00428]\u001b[A\n",
            "Validation after 100 batches:  50%|████████        | 5/10 [00:13<00:11,  2.23s/it, val_loss=0.00428]\u001b[A\n",
            "Validation after 100 batches:  50%|███████▌       | 5/10 [00:13<00:11,  2.23s/it, val_loss=0.000942]\u001b[A\n",
            "Validation after 100 batches:  60%|█████████      | 6/10 [00:13<00:06,  1.51s/it, val_loss=0.000942]\u001b[A\n",
            "Validation after 100 batches:  60%|██████████▏      | 6/10 [00:15<00:06,  1.51s/it, val_loss=0.0837]\u001b[A\n",
            "Validation after 100 batches:  70%|███████████▉     | 7/10 [00:15<00:05,  1.75s/it, val_loss=0.0837]\u001b[A\n",
            "Validation after 100 batches:  70%|███████████▉     | 7/10 [00:15<00:05,  1.75s/it, val_loss=0.0974]\u001b[A\n",
            "Validation after 100 batches:  70%|████████████▌     | 7/10 [00:19<00:05,  1.75s/it, val_loss=0.959]\u001b[A\n",
            "Validation after 100 batches:  90%|████████████████▏ | 9/10 [00:19<00:01,  1.71s/it, val_loss=0.959]\u001b[A\n",
            "Validation after 100 batches: 100%|█████████████████| 10/10 [00:19<00:00,  1.93s/it, val_loss=0.368]\n",
            "Epoch 5/100 Training:  83%|█████████████████▌   | 100/120 [04:29<02:33,  7.67s/it, train_loss=0.023]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 100/120 batches: Val Loss: 0.0487  Val Acc: 0.9313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100 Training:  87%|█████████████████▎  | 104/120 [04:30<00:32,  2.03s/it, train_loss=0.0473]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 101 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 102 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 103 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 104 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  91%|███████████████████  | 109/120 [04:37<00:16,  1.47s/it, train_loss=0.471]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 105 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 106 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 107 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 108 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 109 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  96%|███████████████████▏| 115/120 [04:49<00:07,  1.51s/it, train_loss=0.0429]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 110 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 111 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 112 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 113 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 114 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 115 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Training:  99%|████████████████████▊| 119/120 [04:59<00:01,  1.58s/it, train_loss=0.152]\n",
            "Validation after 120 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 116 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 117 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 118 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 119 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 120 batches:   0%|                         | 0/10 [00:02<?, ?it/s, val_loss=0.0608]\u001b[A\n",
            "Validation after 120 batches:  10%|█▋               | 1/10 [00:02<00:21,  2.37s/it, val_loss=0.0608]\u001b[A\n",
            "Validation after 120 batches:  10%|█▊                | 1/10 [00:02<00:21,  2.37s/it, val_loss=0.277]\u001b[A\n",
            "Validation after 120 batches:  20%|███▌              | 2/10 [00:02<00:08,  1.04s/it, val_loss=0.277]\u001b[A\n",
            "Validation after 120 batches:  20%|███▌              | 2/10 [00:04<00:08,  1.04s/it, val_loss=0.171]\u001b[A\n",
            "Validation after 120 batches:  30%|█████▍            | 3/10 [00:04<00:10,  1.46s/it, val_loss=0.171]\u001b[A\n",
            "Validation after 120 batches:  30%|█████▍            | 3/10 [00:04<00:10,  1.46s/it, val_loss=0.107]\u001b[A\n",
            "Validation after 120 batches:  40%|███████▏          | 4/10 [00:04<00:05,  1.07it/s, val_loss=0.107]\u001b[A\n",
            "Validation after 120 batches:  40%|███████▏          | 4/10 [00:06<00:05,  1.07it/s, val_loss=0.185]\u001b[A\n",
            "Validation after 120 batches:  50%|█████████         | 5/10 [00:06<00:06,  1.32s/it, val_loss=0.185]\u001b[A\n",
            "Validation after 120 batches:  50%|████████▌        | 5/10 [00:06<00:06,  1.32s/it, val_loss=0.0364]\u001b[A\n",
            "Validation after 120 batches:  60%|██████████▏      | 6/10 [00:06<00:03,  1.11it/s, val_loss=0.0364]\u001b[A\n",
            "Validation after 120 batches:  60%|██████████▊       | 6/10 [00:08<00:03,  1.11it/s, val_loss=0.127]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:08<00:03,  1.28s/it, val_loss=0.127]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:08<00:03,  1.28s/it, val_loss=0.126]\u001b[A\n",
            "Validation after 120 batches:  80%|██████████████▍   | 8/10 [00:08<00:01,  1.09it/s, val_loss=0.126]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 120 batches:  80%|██████████████▍   | 8/10 [00:11<00:01,  1.09it/s, val_loss=0.166]\u001b[A\n",
            "Validation after 120 batches:  90%|████████████████▏ | 9/10 [00:11<00:01,  1.60s/it, val_loss=0.166]\u001b[A\n",
            "Validation after 120 batches: 100%|█████████████████| 10/10 [00:12<00:00,  1.21s/it, val_loss=0.328]\n",
            "Epoch 5/100 Training: 100%|█████████████████████| 120/120 [05:11<00:00,  2.60s/it, train_loss=0.152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 120/120 batches: Val Loss: 0.0396  Val Acc: 0.9187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100 Validation:  18%|████▏                   | 7/40 [00:09<00:40,  1.22s/it, val_loss=0.126]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 280. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/100 Validation: 100%|███████████████████████| 40/40 [01:17<00:00,  1.93s/it, val_loss=0.419]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/100] Train Loss: 0.1408  Train Acc: 0.9411 Val Loss: 0.2333  Val Acc: 0.8891\n",
            "⚠️ No improvement in Val Acc for 2 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100 Training:   0%|                                                 | 0/120 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:   4%|▉                      | 5/120 [00:10<03:42,  1.93s/it, train_loss=0.187]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:   9%|██                    | 11/120 [00:21<03:18,  1.82s/it, train_loss=0.244]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 11 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  13%|██▉                   | 16/120 [00:30<03:06,  1.79s/it, train_loss=0.187]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 12 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 13 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 14 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 15 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 16 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  16%|███▍                  | 19/120 [00:38<03:32,  2.11s/it, train_loss=0.168]\n",
            "Validation after 20 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 17 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 18 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 19 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:   0%|                           | 0/10 [00:05<?, ?it/s, val_loss=0.443]\u001b[A\n",
            "Validation after 20 batches:  10%|█▉                 | 1/10 [00:05<00:46,  5.21s/it, val_loss=0.443]\u001b[A\n",
            "Validation after 20 batches:  10%|█▉                 | 1/10 [00:05<00:46,  5.21s/it, val_loss=0.644]\u001b[A\n",
            "Validation after 20 batches:  20%|███▊               | 2/10 [00:05<00:18,  2.25s/it, val_loss=0.644]\u001b[A\n",
            "Validation after 20 batches:  20%|███▊               | 2/10 [00:09<00:18,  2.25s/it, val_loss=0.417]\u001b[A\n",
            "Validation after 20 batches:  30%|█████▋             | 3/10 [00:09<00:20,  2.95s/it, val_loss=0.417]\u001b[A\n",
            "Validation after 20 batches:  30%|█████▋             | 3/10 [00:09<00:20,  2.95s/it, val_loss=0.487]\u001b[A\n",
            "Validation after 20 batches:  40%|███████▌           | 4/10 [00:09<00:11,  1.84s/it, val_loss=0.487]\u001b[A\n",
            "Validation after 20 batches:  40%|███████▌           | 4/10 [00:11<00:11,  1.84s/it, val_loss=0.462]\u001b[A\n",
            "Validation after 20 batches:  50%|█████████▌         | 5/10 [00:11<00:09,  1.98s/it, val_loss=0.462]\u001b[A\n",
            "Validation after 20 batches:  50%|██████████          | 5/10 [00:11<00:09,  1.98s/it, val_loss=0.28]\u001b[A\n",
            "Validation after 20 batches:  60%|████████████        | 6/10 [00:11<00:05,  1.34s/it, val_loss=0.28]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:  60%|███████████▍       | 6/10 [00:14<00:05,  1.34s/it, val_loss=0.397]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:14<00:05,  1.92s/it, val_loss=0.397]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:15<00:05,  1.92s/it, val_loss=0.257]\u001b[A\n",
            "Validation after 20 batches:  80%|███████████████▏   | 8/10 [00:15<00:02,  1.41s/it, val_loss=0.257]\u001b[A\n",
            "Validation after 20 batches:  80%|███████████████▏   | 8/10 [00:17<00:02,  1.41s/it, val_loss=0.349]\u001b[A\n",
            "Validation after 20 batches:  90%|█████████████████  | 9/10 [00:17<00:01,  1.80s/it, val_loss=0.349]\u001b[A\n",
            "Validation after 20 batches:  90%|█████████████████  | 9/10 [00:17<00:01,  1.80s/it, val_loss=0.682]\u001b[A\n",
            "Validation after 20 batches: 100%|██████████████████| 10/10 [00:17<00:00,  1.79s/it, val_loss=0.682]\n",
            "Epoch 6/100 Training:  17%|███▋                  | 20/120 [00:56<12:22,  7.43s/it, train_loss=0.168]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 20/120 batches: Val Loss: 0.1105  Val Acc: 0.7312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100 Training:  22%|████▊                 | 26/120 [01:01<02:45,  1.76s/it, train_loss=0.163]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 21 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 22 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 23 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 24 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 25 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 26 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  26%|█████▋                | 31/120 [01:11<03:12,  2.16s/it, train_loss=0.069]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 27 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 28 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 29 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 30 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 31 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  31%|██████▍              | 37/120 [01:22<02:29,  1.80s/it, train_loss=0.0456]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 32 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 33 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 34 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 35 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 36 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 37 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  32%|██████▊              | 39/120 [01:29<02:31,  1.87s/it, train_loss=0.0436]\n",
            "Validation after 40 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 38 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 39 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:   0%|                          | 0/10 [00:04<?, ?it/s, val_loss=0.0606]\u001b[A\n",
            "Validation after 40 batches:  10%|█▊                | 1/10 [00:04<00:44,  4.90s/it, val_loss=0.0606]\u001b[A\n",
            "Validation after 40 batches:  10%|█▉                 | 1/10 [00:05<00:44,  4.90s/it, val_loss=0.615]\u001b[A\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:05<00:16,  2.10s/it, val_loss=0.615]\u001b[A\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:10<00:16,  2.10s/it, val_loss=0.478]\u001b[A\n",
            "Validation after 40 batches:  30%|█████▋             | 3/10 [00:10<00:26,  3.84s/it, val_loss=0.478]\u001b[A\n",
            "Validation after 40 batches:  30%|█████▋             | 3/10 [00:11<00:26,  3.84s/it, val_loss=0.114]\u001b[A\n",
            "Validation after 40 batches:  40%|███████▌           | 4/10 [00:11<00:14,  2.37s/it, val_loss=0.114]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:  40%|███████▌           | 4/10 [00:14<00:14,  2.37s/it, val_loss=0.289]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████▌         | 5/10 [00:14<00:13,  2.69s/it, val_loss=0.289]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████         | 5/10 [00:14<00:13,  2.69s/it, val_loss=0.0258]\u001b[A\n",
            "Validation after 40 batches:  60%|██████████▊       | 6/10 [00:14<00:07,  1.81s/it, val_loss=0.0258]\u001b[A\n",
            "Validation after 40 batches:  60%|███████████▍       | 6/10 [00:16<00:07,  1.81s/it, val_loss=0.237]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:16<00:05,  1.89s/it, val_loss=0.237]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:16<00:05,  1.89s/it, val_loss=0.156]\u001b[A\n",
            "Validation after 40 batches:  80%|███████████████▏   | 8/10 [00:16<00:02,  1.32s/it, val_loss=0.156]\u001b[A\n",
            "Validation after 40 batches:  80%|███████████████▏   | 8/10 [00:18<00:02,  1.32s/it, val_loss=0.416]\u001b[A\n",
            "Validation after 40 batches:  90%|█████████████████  | 9/10 [00:18<00:01,  1.44s/it, val_loss=0.416]\u001b[A\n",
            "Validation after 40 batches: 100%|██████████████████| 10/10 [00:18<00:00,  1.84s/it, val_loss=0.574]\n",
            "Epoch 6/100 Training:  33%|███████              | 40/120 [01:48<10:28,  7.85s/it, train_loss=0.0436]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 40/120 batches: Val Loss: 0.0741  Val Acc: 0.9062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100 Training:  37%|████████              | 44/120 [01:49<02:37,  2.08s/it, train_loss=0.111]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 41 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 42 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 43 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 44 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  41%|████████▉             | 49/120 [01:59<02:03,  1.74s/it, train_loss=0.085]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 45 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 46 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 47 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 48 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 49 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  46%|█████████▋           | 55/120 [02:12<02:01,  1.87s/it, train_loss=0.0854]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 50 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 51 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 52 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 53 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 54 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 55 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  49%|██████████▎          | 59/120 [02:18<01:32,  1.51s/it, train_loss=0.0003]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 56 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 57 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 58 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 59 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  49%|██████████▊           | 59/120 [02:23<01:32,  1.51s/it, train_loss=0.147]\n",
            "Validation after 60 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 60 batches:   0%|                        | 0/10 [00:04<?, ?it/s, val_loss=0.000393]\u001b[A\n",
            "Validation after 60 batches:  10%|█▌              | 1/10 [00:04<00:44,  4.99s/it, val_loss=0.000393]\u001b[A\n",
            "Validation after 60 batches:  10%|█▉                 | 1/10 [00:05<00:44,  4.99s/it, val_loss=0.633]\u001b[A\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:05<00:17,  2.14s/it, val_loss=0.633]\u001b[A\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:08<00:17,  2.14s/it, val_loss=0.375]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▋             | 3/10 [00:08<00:17,  2.51s/it, val_loss=0.375]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▍            | 3/10 [00:08<00:17,  2.51s/it, val_loss=0.0227]\u001b[A\n",
            "Validation after 60 batches:  40%|███████▏          | 4/10 [00:08<00:09,  1.57s/it, val_loss=0.0227]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:  40%|███████▌           | 4/10 [00:10<00:09,  1.57s/it, val_loss=0.143]\u001b[A\n",
            "Validation after 60 batches:  50%|█████████▌         | 5/10 [00:10<00:08,  1.79s/it, val_loss=0.143]\u001b[A\n",
            "Validation after 60 batches:  50%|████████        | 5/10 [00:10<00:08,  1.79s/it, val_loss=0.000473]\u001b[A\n",
            "Validation after 60 batches:  60%|█████████▌      | 6/10 [00:10<00:04,  1.23s/it, val_loss=0.000473]\u001b[A\n",
            "Validation after 60 batches:  60%|██████████▊       | 6/10 [00:13<00:04,  1.23s/it, val_loss=0.0896]\u001b[A\n",
            "Validation after 60 batches:  70%|████████████▌     | 7/10 [00:13<00:05,  1.74s/it, val_loss=0.0896]\u001b[A\n",
            "Validation after 60 batches:  70%|██████████████      | 7/10 [00:13<00:05,  1.74s/it, val_loss=0.18]\u001b[A\n",
            "Validation after 60 batches:  80%|████████████████    | 8/10 [00:13<00:02,  1.23s/it, val_loss=0.18]\u001b[A\n",
            "Validation after 60 batches:  80%|██████████████████▍    | 8/10 [00:16<00:02,  1.23s/it, val_loss=1]\u001b[A\n",
            "Validation after 60 batches:  90%|████████████████████▋  | 9/10 [00:16<00:01,  1.79s/it, val_loss=1]\u001b[A\n",
            "Validation after 60 batches: 100%|██████████████████| 10/10 [00:16<00:00,  1.66s/it, val_loss=0.249]\n",
            "Epoch 6/100 Training:  50%|███████████           | 60/120 [02:39<07:25,  7.42s/it, train_loss=0.147]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 60/120 batches: Val Loss: 0.0673  Val Acc: 0.9125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100 Training:  53%|███████████▋          | 64/120 [02:40<01:50,  1.97s/it, train_loss=0.131]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 61 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 62 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 63 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 64 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  58%|████████████▊         | 70/120 [02:50<01:15,  1.51s/it, train_loss=0.197]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 65 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 66 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 67 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 68 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 69 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 70 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  62%|█████████████▏       | 75/120 [03:00<01:06,  1.47s/it, train_loss=0.0874]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 71 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 72 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 73 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 74 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 75 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  66%|█████████████▊       | 79/120 [03:11<01:30,  2.20s/it, train_loss=0.0448]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 76 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 77 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 78 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 79 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  66%|██████████████▍       | 79/120 [03:14<01:30,  2.20s/it, train_loss=0.039]\n",
            "Validation after 80 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 80 batches:   0%|                          | 0/10 [00:04<?, ?it/s, val_loss=0.0166]\u001b[A\n",
            "Validation after 80 batches:  10%|█▊                | 1/10 [00:04<00:40,  4.52s/it, val_loss=0.0166]\u001b[A\n",
            "Validation after 80 batches:  10%|█▉                 | 1/10 [00:04<00:40,  4.52s/it, val_loss=0.282]\u001b[A\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:04<00:15,  1.93s/it, val_loss=0.282]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:09<00:15,  1.93s/it, val_loss=0.146]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▋             | 3/10 [00:09<00:23,  3.36s/it, val_loss=0.146]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▍            | 3/10 [00:09<00:23,  3.36s/it, val_loss=0.0194]\u001b[A\n",
            "Validation after 80 batches:  40%|███████▏          | 4/10 [00:09<00:12,  2.08s/it, val_loss=0.0194]\u001b[A\n",
            "Validation after 80 batches:  40%|███████▌           | 4/10 [00:12<00:12,  2.08s/it, val_loss=0.107]\u001b[A\n",
            "Validation after 80 batches:  50%|█████████▌         | 5/10 [00:12<00:11,  2.32s/it, val_loss=0.107]\u001b[A\n",
            "Validation after 80 batches:  50%|█████████         | 5/10 [00:13<00:11,  2.32s/it, val_loss=0.0182]\u001b[A\n",
            "Validation after 80 batches:  60%|██████████▊       | 6/10 [00:13<00:06,  1.69s/it, val_loss=0.0182]\u001b[A\n",
            "Validation after 80 batches:  60%|███████████▍       | 6/10 [00:14<00:06,  1.69s/it, val_loss=0.132]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:14<00:05,  1.71s/it, val_loss=0.132]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:15<00:05,  1.71s/it, val_loss=0.149]\u001b[A\n",
            "Validation after 80 batches:  80%|███████████████▏   | 8/10 [00:15<00:02,  1.29s/it, val_loss=0.149]\u001b[A\n",
            "Validation after 80 batches:  80%|███████████████▏   | 8/10 [00:16<00:02,  1.29s/it, val_loss=0.331]\u001b[A\n",
            "Validation after 80 batches:  90%|█████████████████  | 9/10 [00:16<00:01,  1.40s/it, val_loss=0.331]\u001b[A\n",
            "Validation after 80 batches:  90%|█████████████████  | 9/10 [00:17<00:01,  1.40s/it, val_loss=0.249]\u001b[A\n",
            "Validation after 80 batches: 100%|██████████████████| 10/10 [00:17<00:00,  1.71s/it, val_loss=0.249]\n",
            "Epoch 6/100 Training:  67%|██████████████▋       | 80/120 [03:31<05:03,  7.60s/it, train_loss=0.039]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 80/120 batches: Val Loss: 0.0363  Val Acc: 0.9313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100 Training:  69%|██████████████▌      | 83/120 [03:32<01:42,  2.78s/it, train_loss=0.0341]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 81 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 82 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 83 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  73%|██████████████▋     | 88/120 [03:41<00:58,  1.83s/it, train_loss=0.00839]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 84 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 85 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 86 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 87 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 88 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  77%|████████████████▊     | 92/120 [03:47<00:42,  1.51s/it, train_loss=0.273]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 89 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 90 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 91 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 92 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  82%|█████████████████▎   | 99/120 [04:02<00:40,  1.93s/it, train_loss=0.0907]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 93 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 94 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 95 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 96 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 97 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 98 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 99 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  82%|█████████████████▎   | 99/120 [04:02<00:40,  1.93s/it, train_loss=0.0143]\n",
            "Validation after 100 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 100 batches:   0%|                          | 0/10 [00:06<?, ?it/s, val_loss=0.137]\u001b[A\n",
            "Validation after 100 batches:  10%|█▊                | 1/10 [00:06<00:57,  6.41s/it, val_loss=0.137]\u001b[A\n",
            "Validation after 100 batches:  10%|█▊                | 1/10 [00:06<00:57,  6.41s/it, val_loss=0.645]\u001b[A\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:06<00:21,  2.73s/it, val_loss=0.645]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:10<00:21,  2.73s/it, val_loss=0.263]\u001b[A\n",
            "Validation after 100 batches:  30%|█████▍            | 3/10 [00:10<00:23,  3.35s/it, val_loss=0.263]\u001b[A\n",
            "Validation after 100 batches:  30%|████▊           | 3/10 [00:10<00:23,  3.35s/it, val_loss=0.00993]\u001b[A\n",
            "Validation after 100 batches:  40%|██████▍         | 4/10 [00:10<00:12,  2.09s/it, val_loss=0.00993]\u001b[A\n",
            "Validation after 100 batches:  40%|███████▏          | 4/10 [00:14<00:12,  2.09s/it, val_loss=0.237]\u001b[A\n",
            "Validation after 100 batches:  50%|█████████         | 5/10 [00:14<00:13,  2.73s/it, val_loss=0.237]\u001b[A\n",
            "Validation after 100 batches:  50%|████████▌        | 5/10 [00:14<00:13,  2.73s/it, val_loss=0.0214]\u001b[A\n",
            "Validation after 100 batches:  60%|██████████▏      | 6/10 [00:14<00:07,  1.85s/it, val_loss=0.0214]\u001b[A\n",
            "Validation after 100 batches:  60%|██████████▊       | 6/10 [00:18<00:07,  1.85s/it, val_loss=0.354]\u001b[A\n",
            "Validation after 100 batches:  70%|████████████▌     | 7/10 [00:18<00:06,  2.30s/it, val_loss=0.354]\u001b[A\n",
            "Validation after 100 batches:  70%|███████████▉     | 7/10 [00:18<00:06,  2.30s/it, val_loss=0.0778]\u001b[A\n",
            "Validation after 100 batches:  80%|█████████████▌   | 8/10 [00:18<00:03,  1.64s/it, val_loss=0.0778]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 100 batches:  80%|██████████████▍   | 8/10 [00:21<00:03,  1.64s/it, val_loss=0.185]\u001b[A\n",
            "Validation after 100 batches:  90%|████████████████▏ | 9/10 [00:21<00:02,  2.02s/it, val_loss=0.185]\u001b[A\n",
            "Validation after 100 batches: 100%|█████████████████| 10/10 [00:21<00:00,  2.13s/it, val_loss=0.513]\n",
            "Epoch 6/100 Training:  83%|████████████████▋   | 100/120 [04:24<02:38,  7.93s/it, train_loss=0.0143]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 100/120 batches: Val Loss: 0.0611  Val Acc: 0.9125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100 Training:  90%|██████████████████  | 108/120 [04:32<00:21,  1.82s/it, train_loss=0.0304]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 101 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 102 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 103 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 104 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 105 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 106 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 107 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 108 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  92%|██████████████████▌ | 111/120 [04:39<00:19,  2.15s/it, train_loss=0.0252]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 109 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 110 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 111 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  97%|████████████████████▎| 116/120 [04:48<00:07,  1.91s/it, train_loss=0.216]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 112 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 113 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 114 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 115 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 116 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Training:  99%|█████████████████████▊| 119/120 [04:56<00:02,  2.20s/it, train_loss=0.14]\n",
            "Validation after 120 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 120 batches:   0%|                          | 0/10 [00:02<?, ?it/s, val_loss=0.264]\u001b[A\n",
            "Validation after 120 batches:  10%|█▊                | 1/10 [00:02<00:20,  2.30s/it, val_loss=0.264]\u001b[A\n",
            "Validation after 120 batches:  10%|█▊                | 1/10 [00:02<00:20,  2.30s/it, val_loss=0.848]\u001b[A\n",
            "Validation after 120 batches:  20%|███▌              | 2/10 [00:02<00:08,  1.01s/it, val_loss=0.848]\u001b[A\n",
            "Validation after 120 batches:  20%|███▌              | 2/10 [00:04<00:08,  1.01s/it, val_loss=0.581]\u001b[A\n",
            "Validation after 120 batches:  30%|█████▍            | 3/10 [00:04<00:09,  1.42s/it, val_loss=0.581]\u001b[A\n",
            "Validation after 120 batches:  30%|█████            | 3/10 [00:04<00:09,  1.42s/it, val_loss=0.0438]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 117 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 118 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 119 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 120 batches:  30%|█████▍            | 3/10 [00:06<00:09,  1.42s/it, val_loss=0.399]\u001b[A\n",
            "Validation after 120 batches:  50%|█████████         | 5/10 [00:06<00:06,  1.23s/it, val_loss=0.399]\u001b[A\n",
            "Validation after 120 batches:  50%|████████▌        | 5/10 [00:06<00:06,  1.23s/it, val_loss=0.0204]\u001b[A\n",
            "Validation after 120 batches:  60%|██████████▏      | 6/10 [00:06<00:03,  1.10it/s, val_loss=0.0204]\u001b[A\n",
            "Validation after 120 batches:  60%|██████████▊       | 6/10 [00:10<00:03,  1.10it/s, val_loss=0.395]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:10<00:04,  1.65s/it, val_loss=0.395]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:10<00:04,  1.65s/it, val_loss=0.147]\u001b[A\n",
            "Validation after 120 batches:  80%|██████████████▍   | 8/10 [00:10<00:02,  1.20s/it, val_loss=0.147]\u001b[A\n",
            "Validation after 120 batches:  80%|██████████████▍   | 8/10 [00:12<00:02,  1.20s/it, val_loss=0.283]\u001b[A\n",
            "Validation after 120 batches:  90%|████████████████▏ | 9/10 [00:12<00:01,  1.54s/it, val_loss=0.283]\u001b[A\n",
            "Validation after 120 batches: 100%|█████████████████| 10/10 [00:12<00:00,  1.27s/it, val_loss=0.872]\n",
            "Epoch 6/100 Training: 100%|██████████████████████| 120/120 [05:09<00:00,  2.58s/it, train_loss=0.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 120/120 batches: Val Loss: 0.0963  Val Acc: 0.8812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100 Validation:   5%|█▏                      | 2/40 [00:02<00:37,  1.02it/s, val_loss=0.848]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 320. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/100 Validation: 100%|████████████████████████| 40/40 [01:18<00:00,  1.95s/it, val_loss=1.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/100] Train Loss: 0.1090  Train Acc: 0.9578 Val Loss: 0.4586  Val Acc: 0.8828\n",
            "⚠️ No improvement in Val Acc for 3 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100 Training:   2%|▍                      | 2/120 [00:03<03:07,  1.59s/it, train_loss=0.105]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:   6%|█▎                    | 7/120 [00:14<03:28,  1.84s/it, train_loss=0.0913]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  10%|██▏                   | 12/120 [00:24<04:09,  2.31s/it, train_loss=0.155]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 11 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 12 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  15%|███▏                 | 18/120 [00:33<02:54,  1.71s/it, train_loss=0.0779]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 13 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 14 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 15 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 16 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 17 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 18 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  16%|███▍                  | 19/120 [00:39<03:24,  2.03s/it, train_loss=0.363]\n",
            "Validation after 20 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 20 batches:   0%|                          | 0/10 [00:04<?, ?it/s, val_loss=0.0103]\u001b[A\n",
            "Validation after 20 batches:  10%|█▊                | 1/10 [00:04<00:41,  4.60s/it, val_loss=0.0103]\u001b[A\n",
            "Validation after 20 batches:  10%|█▉                 | 1/10 [00:04<00:41,  4.60s/it, val_loss=0.279]\u001b[A\n",
            "Validation after 20 batches:  20%|███▊               | 2/10 [00:04<00:15,  1.97s/it, val_loss=0.279]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 19 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:  20%|███▊               | 2/10 [00:07<00:15,  1.97s/it, val_loss=0.202]\u001b[A\n",
            "Validation after 20 batches:  30%|█████▋             | 3/10 [00:07<00:16,  2.36s/it, val_loss=0.202]\u001b[A\n",
            "Validation after 20 batches:  30%|█████▍            | 3/10 [00:08<00:16,  2.36s/it, val_loss=0.0161]\u001b[A\n",
            "Validation after 20 batches:  40%|███████▏          | 4/10 [00:08<00:09,  1.63s/it, val_loss=0.0161]\u001b[A\n",
            "Validation after 20 batches:  40%|███████▌           | 4/10 [00:11<00:09,  1.63s/it, val_loss=0.115]\u001b[A\n",
            "Validation after 20 batches:  50%|█████████▌         | 5/10 [00:11<00:11,  2.38s/it, val_loss=0.115]\u001b[A\n",
            "Validation after 20 batches:  50%|████████▌        | 5/10 [00:13<00:11,  2.38s/it, val_loss=0.00534]\u001b[A\n",
            "Validation after 20 batches:  60%|██████████▏      | 6/10 [00:13<00:08,  2.04s/it, val_loss=0.00534]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:  60%|██████████▊       | 6/10 [00:15<00:08,  2.04s/it, val_loss=0.0316]\u001b[A\n",
            "Validation after 20 batches:  70%|████████████▌     | 7/10 [00:15<00:06,  2.09s/it, val_loss=0.0316]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:15<00:06,  2.09s/it, val_loss=0.221]\u001b[A\n",
            "Validation after 20 batches:  80%|███████████████▏   | 8/10 [00:15<00:03,  1.52s/it, val_loss=0.221]\u001b[A\n",
            "Validation after 20 batches:  80%|███████████████▏   | 8/10 [00:17<00:03,  1.52s/it, val_loss=0.497]\u001b[A\n",
            "Validation after 20 batches:  90%|█████████████████  | 9/10 [00:17<00:01,  1.62s/it, val_loss=0.497]\u001b[A\n",
            "Validation after 20 batches:  90%|█████████████████  | 9/10 [00:17<00:01,  1.62s/it, val_loss=0.254]\u001b[A\n",
            "Validation after 20 batches: 100%|██████████████████| 10/10 [00:17<00:00,  1.78s/it, val_loss=0.254]\n",
            "Epoch 7/100 Training:  17%|███▋                  | 20/120 [00:57<12:53,  7.74s/it, train_loss=0.363]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 20/120 batches: Val Loss: 0.0408  Val Acc: 0.9313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100 Training:  22%|████▊                 | 26/120 [01:01<02:41,  1.72s/it, train_loss=0.188]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 21 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 22 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 23 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 24 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 25 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 26 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  26%|█████▉                 | 31/120 [01:14<03:21,  2.27s/it, train_loss=0.12]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 27 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 28 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 29 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 30 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 31 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  30%|██████▌               | 36/120 [01:24<02:48,  2.01s/it, train_loss=0.153]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 32 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 33 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 34 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 35 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 36 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  32%|██████▊              | 39/120 [01:31<03:09,  2.34s/it, train_loss=0.0499]\n",
            "Validation after 40 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 37 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 38 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 39 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:   0%|                        | 0/10 [00:06<?, ?it/s, val_loss=0.000272]\u001b[A\n",
            "Validation after 40 batches:  10%|█▌              | 1/10 [00:06<00:59,  6.59s/it, val_loss=0.000272]\u001b[A\n",
            "Validation after 40 batches:  10%|█▉                 | 1/10 [00:06<00:59,  6.59s/it, val_loss=0.244]\u001b[A\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:06<00:22,  2.78s/it, val_loss=0.244]\u001b[A\n",
            "Validation after 40 batches:  20%|███▌              | 2/10 [00:10<00:22,  2.78s/it, val_loss=0.0589]\u001b[A\n",
            "Validation after 40 batches:  30%|█████▍            | 3/10 [00:10<00:23,  3.37s/it, val_loss=0.0589]\u001b[A\n",
            "Validation after 40 batches:  30%|█████            | 3/10 [00:10<00:23,  3.37s/it, val_loss=0.00034]\u001b[A\n",
            "Validation after 40 batches:  40%|██████▊          | 4/10 [00:10<00:12,  2.09s/it, val_loss=0.00034]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:  40%|███████▏          | 4/10 [00:15<00:12,  2.09s/it, val_loss=0.0127]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████         | 5/10 [00:15<00:14,  2.84s/it, val_loss=0.0127]\u001b[A\n",
            "Validation after 40 batches:  50%|████████        | 5/10 [00:15<00:14,  2.84s/it, val_loss=0.000163]\u001b[A\n",
            "Validation after 40 batches:  60%|█████████▌      | 6/10 [00:15<00:07,  1.92s/it, val_loss=0.000163]\u001b[A\n",
            "Validation after 40 batches:  60%|██████████▊       | 6/10 [00:19<00:07,  1.92s/it, val_loss=0.0433]\u001b[A\n",
            "Validation after 40 batches:  70%|████████████▌     | 7/10 [00:19<00:07,  2.55s/it, val_loss=0.0433]\u001b[A\n",
            "Validation after 40 batches:  70%|████████████▌     | 7/10 [00:19<00:07,  2.55s/it, val_loss=0.0544]\u001b[A\n",
            "Validation after 40 batches:  80%|██████████████▍   | 8/10 [00:19<00:03,  1.78s/it, val_loss=0.0544]\u001b[A\n",
            "Validation after 40 batches:  80%|███████████████▏   | 8/10 [00:21<00:03,  1.78s/it, val_loss=0.632]\u001b[A\n",
            "Validation after 40 batches:  90%|█████████████████  | 9/10 [00:21<00:02,  2.04s/it, val_loss=0.632]\u001b[A\n",
            "Validation after 40 batches: 100%|██████████████████| 10/10 [00:21<00:00,  2.19s/it, val_loss=0.137]\n",
            "Epoch 7/100 Training:  33%|███████              | 40/120 [01:53<11:03,  8.29s/it, train_loss=0.0499]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 40/120 batches: Val Loss: 0.0296  Val Acc: 0.9688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100 Training:  37%|███████▋             | 44/120 [01:54<02:46,  2.19s/it, train_loss=0.0025]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 41 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 42 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 43 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 44 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  41%|████████▌            | 49/120 [02:03<02:21,  1.99s/it, train_loss=0.0426]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 45 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 46 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 47 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 48 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 49 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  46%|█████████▋           | 55/120 [02:14<01:43,  1.60s/it, train_loss=0.0218]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 50 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 51 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 52 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 53 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 54 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 55 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  49%|██████████▎          | 59/120 [02:24<02:10,  2.13s/it, train_loss=0.0463]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 56 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 57 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 58 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 59 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  49%|██████████▎          | 59/120 [02:27<02:10,  2.13s/it, train_loss=0.0461]\n",
            "Validation after 60 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 60 batches:   0%|                          | 0/10 [00:03<?, ?it/s, val_loss=0.0234]\u001b[A\n",
            "Validation after 60 batches:  10%|█▊                | 1/10 [00:03<00:33,  3.69s/it, val_loss=0.0234]\u001b[A\n",
            "Validation after 60 batches:  10%|█▉                 | 1/10 [00:03<00:33,  3.69s/it, val_loss=0.554]\u001b[A\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:03<00:12,  1.59s/it, val_loss=0.554]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:07<00:12,  1.59s/it, val_loss=0.296]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▋             | 3/10 [00:07<00:19,  2.75s/it, val_loss=0.296]\u001b[A\n",
            "Validation after 60 batches:  30%|████▊           | 3/10 [00:08<00:19,  2.75s/it, val_loss=0.000927]\u001b[A\n",
            "Validation after 60 batches:  40%|██████▍         | 4/10 [00:08<00:10,  1.72s/it, val_loss=0.000927]\u001b[A\n",
            "Validation after 60 batches:  40%|███████▌           | 4/10 [00:11<00:10,  1.72s/it, val_loss=0.188]\u001b[A\n",
            "Validation after 60 batches:  50%|█████████▌         | 5/10 [00:11<00:11,  2.25s/it, val_loss=0.188]\u001b[A\n",
            "Validation after 60 batches:  50%|████████▌        | 5/10 [00:11<00:11,  2.25s/it, val_loss=0.00335]\u001b[A\n",
            "Validation after 60 batches:  60%|██████████▏      | 6/10 [00:11<00:06,  1.54s/it, val_loss=0.00335]\u001b[A\n",
            "Validation after 60 batches:  60%|███████████▍       | 6/10 [00:13<00:06,  1.54s/it, val_loss=0.126]\u001b[A\n",
            "Validation after 60 batches:  70%|█████████████▎     | 7/10 [00:13<00:05,  1.67s/it, val_loss=0.126]\u001b[A\n",
            "Validation after 60 batches:  70%|█████████████▎     | 7/10 [00:13<00:05,  1.67s/it, val_loss=0.195]\u001b[A\n",
            "Validation after 60 batches:  80%|███████████████▏   | 8/10 [00:13<00:02,  1.19s/it, val_loss=0.195]\u001b[A\n",
            "Validation after 60 batches:  80%|███████████████▏   | 8/10 [00:15<00:02,  1.19s/it, val_loss=0.673]\u001b[A\n",
            "Validation after 60 batches:  90%|█████████████████  | 9/10 [00:15<00:01,  1.42s/it, val_loss=0.673]\u001b[A\n",
            "Validation after 60 batches: 100%|██████████████████| 10/10 [00:15<00:00,  1.56s/it, val_loss=0.449]\n",
            "Epoch 7/100 Training:  50%|██████████▌          | 60/120 [02:42<07:05,  7.10s/it, train_loss=0.0461]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 60/120 batches: Val Loss: 0.0627  Val Acc: 0.9125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100 Training:  53%|███████████▏         | 64/120 [02:43<01:46,  1.90s/it, train_loss=0.0181]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 61 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 62 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 63 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 64 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  57%|████████████▋         | 69/120 [02:53<01:53,  2.22s/it, train_loss=0.002]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 65 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 66 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 67 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 68 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 69 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  62%|████████████▉        | 74/120 [03:01<01:18,  1.71s/it, train_loss=0.0969]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 70 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 71 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 72 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 73 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 74 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  66%|█████████████▏      | 79/120 [03:12<01:20,  1.96s/it, train_loss=0.00396]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 75 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 76 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 77 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 78 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 79 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  66%|█████████████▊       | 79/120 [03:15<01:20,  1.96s/it, train_loss=0.0017]\n",
            "Validation after 80 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 80 batches:   0%|                           | 0/10 [00:06<?, ?it/s, val_loss=0.252]\u001b[A\n",
            "Validation after 80 batches:  10%|█▉                 | 1/10 [00:06<00:58,  6.51s/it, val_loss=0.252]\u001b[A\n",
            "Validation after 80 batches:  10%|█▉                 | 1/10 [00:06<00:58,  6.51s/it, val_loss=0.494]\u001b[A\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:06<00:22,  2.75s/it, val_loss=0.494]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:10<00:22,  2.75s/it, val_loss=0.422]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▋             | 3/10 [00:10<00:21,  3.06s/it, val_loss=0.422]\u001b[A\n",
            "Validation after 80 batches:  30%|████▊           | 3/10 [00:10<00:21,  3.06s/it, val_loss=0.000119]\u001b[A\n",
            "Validation after 80 batches:  40%|██████▍         | 4/10 [00:10<00:11,  1.90s/it, val_loss=0.000119]\u001b[A\n",
            "Validation after 80 batches:  40%|███████▌           | 4/10 [00:13<00:11,  1.90s/it, val_loss=0.203]\u001b[A\n",
            "Validation after 80 batches:  50%|█████████▌         | 5/10 [00:13<00:11,  2.30s/it, val_loss=0.203]\u001b[A\n",
            "Validation after 80 batches:  50%|████████        | 5/10 [00:13<00:11,  2.30s/it, val_loss=0.000661]\u001b[A\n",
            "Validation after 80 batches:  60%|█████████▌      | 6/10 [00:13<00:06,  1.56s/it, val_loss=0.000661]\u001b[A\n",
            "Validation after 80 batches:  60%|███████████▍       | 6/10 [00:15<00:06,  1.56s/it, val_loss=0.186]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:15<00:05,  1.72s/it, val_loss=0.186]\u001b[A\n",
            "Validation after 80 batches:  70%|██████████████      | 7/10 [00:15<00:05,  1.72s/it, val_loss=0.22]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:18<00:05,  1.72s/it, val_loss=0.673]\u001b[A\n",
            "Validation after 80 batches:  90%|█████████████████  | 9/10 [00:18<00:01,  1.62s/it, val_loss=0.673]\u001b[A\n",
            "Validation after 80 batches: 100%|██████████████████| 10/10 [00:18<00:00,  1.85s/it, val_loss=0.734]\n",
            "Epoch 7/100 Training:  67%|██████████████       | 80/120 [03:33<05:03,  7.59s/it, train_loss=0.0017]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 80/120 batches: Val Loss: 0.0796  Val Acc: 0.9250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100 Training:  70%|██████████████      | 84/120 [03:34<01:13,  2.04s/it, train_loss=0.00933]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 81 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 82 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 83 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 84 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  74%|████████████████▎     | 89/120 [03:43<00:47,  1.54s/it, train_loss=0.408]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 85 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 86 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 87 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 88 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 89 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  79%|████████████████▋    | 95/120 [03:54<00:43,  1.76s/it, train_loss=0.0455]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 90 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 91 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 92 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 93 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 94 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 95 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  82%|██████████████████▏   | 99/120 [04:04<00:55,  2.63s/it, train_loss=0.033]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 96 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 97 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 98 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 99 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  82%|█████████████████▎   | 99/120 [04:04<00:55,  2.63s/it, train_loss=0.0382]\n",
            "Validation after 100 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 100 batches:   0%|                         | 0/10 [00:05<?, ?it/s, val_loss=0.0721]\u001b[A\n",
            "Validation after 100 batches:  10%|█▋               | 1/10 [00:05<00:45,  5.07s/it, val_loss=0.0721]\u001b[A\n",
            "Validation after 100 batches:  10%|██                  | 1/10 [00:05<00:45,  5.07s/it, val_loss=0.6]\u001b[A\n",
            "Validation after 100 batches:  20%|████                | 2/10 [00:05<00:17,  2.19s/it, val_loss=0.6]\u001b[A\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:09<00:17,  2.19s/it, val_loss=0.437]\u001b[A\n",
            "Validation after 100 batches:  30%|█████▍            | 3/10 [00:09<00:20,  2.97s/it, val_loss=0.437]\u001b[A\n",
            "Validation after 100 batches:  30%|█████▍            | 3/10 [00:09<00:20,  2.97s/it, val_loss=0.195]\u001b[A\n",
            "Validation after 100 batches:  40%|███████▏          | 4/10 [00:09<00:11,  1.84s/it, val_loss=0.195]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 100 batches:  40%|███████▏          | 4/10 [00:13<00:11,  1.84s/it, val_loss=0.258]\u001b[A\n",
            "Validation after 100 batches:  50%|█████████         | 5/10 [00:13<00:13,  2.76s/it, val_loss=0.258]\u001b[A\n",
            "Validation after 100 batches:  50%|████████        | 5/10 [00:13<00:13,  2.76s/it, val_loss=0.00837]\u001b[A\n",
            "Validation after 100 batches:  60%|█████████▌      | 6/10 [00:13<00:07,  1.87s/it, val_loss=0.00837]\u001b[A\n",
            "Validation after 100 batches:  60%|██████████▊       | 6/10 [00:17<00:07,  1.87s/it, val_loss=0.167]\u001b[A\n",
            "Validation after 100 batches:  70%|████████████▌     | 7/10 [00:17<00:07,  2.44s/it, val_loss=0.167]\u001b[A\n",
            "Validation after 100 batches:  70%|████████████▌     | 7/10 [00:17<00:07,  2.44s/it, val_loss=0.125]\u001b[A\n",
            "Validation after 100 batches:  80%|██████████████▍   | 8/10 [00:17<00:03,  1.70s/it, val_loss=0.125]\u001b[A\n",
            "Validation after 100 batches:  80%|██████████████▍   | 8/10 [00:19<00:03,  1.70s/it, val_loss=0.243]\u001b[A\n",
            "Validation after 100 batches:  90%|████████████████▏ | 9/10 [00:19<00:01,  1.72s/it, val_loss=0.243]\u001b[A\n",
            "Validation after 100 batches: 100%|█████████████████| 10/10 [00:19<00:00,  1.94s/it, val_loss=0.616]\n",
            "Epoch 7/100 Training:  83%|████████████████▋   | 100/120 [04:24<02:35,  7.76s/it, train_loss=0.0382]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 100/120 batches: Val Loss: 0.0680  Val Acc: 0.8875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100 Training:  84%|████████████████▊   | 101/120 [04:24<01:44,  5.51s/it, train_loss=0.0993]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 101 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  90%|██████████████████  | 108/120 [04:33<00:25,  2.12s/it, train_loss=0.0669]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 102 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 103 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 104 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 105 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 106 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 107 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 108 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  94%|███████████████████▊ | 113/120 [04:44<00:14,  2.06s/it, train_loss=0.183]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 109 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 110 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 111 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 112 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 113 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 114 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  98%|███████████████████▋| 118/120 [04:53<00:03,  1.55s/it, train_loss=0.0199]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 115 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 116 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 117 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 118 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Training:  99%|████████████████████▊| 119/120 [04:56<00:02,  2.06s/it, train_loss=0.304]\n",
            "Validation after 120 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 120 batches:   0%|                         | 0/10 [00:02<?, ?it/s, val_loss=0.0623]\u001b[A\n",
            "Validation after 120 batches:  10%|█▋               | 1/10 [00:02<00:21,  2.44s/it, val_loss=0.0623]\u001b[A\n",
            "Validation after 120 batches:  10%|█▊                | 1/10 [00:02<00:21,  2.44s/it, val_loss=0.646]\u001b[A\n",
            "Validation after 120 batches:  20%|███▌              | 2/10 [00:02<00:08,  1.07s/it, val_loss=0.646]\u001b[A\n",
            "Validation after 120 batches:  20%|███▌              | 2/10 [00:05<00:08,  1.07s/it, val_loss=0.547]\u001b[A\n",
            "Validation after 120 batches:  30%|█████▍            | 3/10 [00:05<00:13,  1.86s/it, val_loss=0.547]\u001b[A\n",
            "Validation after 120 batches:  30%|█████            | 3/10 [00:05<00:13,  1.86s/it, val_loss=0.0802]\u001b[A\n",
            "Validation after 120 batches:  40%|██████▊          | 4/10 [00:05<00:07,  1.17s/it, val_loss=0.0802]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 119 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 120 batches:  40%|███████▏          | 4/10 [00:08<00:07,  1.17s/it, val_loss=0.539]\u001b[A\n",
            "Validation after 120 batches:  50%|█████████         | 5/10 [00:08<00:09,  1.86s/it, val_loss=0.539]\u001b[A\n",
            "Validation after 120 batches:  50%|████████▌        | 5/10 [00:08<00:09,  1.86s/it, val_loss=0.0247]\u001b[A\n",
            "Validation after 120 batches:  60%|██████████▏      | 6/10 [00:08<00:05,  1.27s/it, val_loss=0.0247]\u001b[A\n",
            "Validation after 120 batches:  60%|██████████▊       | 6/10 [00:10<00:05,  1.27s/it, val_loss=0.356]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:10<00:04,  1.55s/it, val_loss=0.356]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:10<00:04,  1.55s/it, val_loss=0.113]\u001b[A\n",
            "Validation after 120 batches:  80%|██████████████▍   | 8/10 [00:10<00:02,  1.09s/it, val_loss=0.113]\u001b[A\n",
            "Validation after 120 batches:  80%|██████████████▍   | 8/10 [00:12<00:02,  1.09s/it, val_loss=0.418]\u001b[A\n",
            "Validation after 120 batches:  90%|████████████████▏ | 9/10 [00:12<00:01,  1.33s/it, val_loss=0.418]\u001b[A\n",
            "Validation after 120 batches: 100%|█████████████████| 10/10 [00:12<00:00,  1.29s/it, val_loss=0.674]\n",
            "Epoch 7/100 Training: 100%|█████████████████████| 120/120 [05:09<00:00,  2.58s/it, train_loss=0.304]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 120/120 batches: Val Loss: 0.0865  Val Acc: 0.8875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100 Validation:   8%|█▋                     | 3/40 [00:04<00:53,  1.43s/it, val_loss=0.0802]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 360. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/100 Validation: 100%|███████████████████████| 40/40 [01:18<00:00,  1.95s/it, val_loss=0.695]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/100] Train Loss: 0.0864  Train Acc: 0.9698 Val Loss: 0.3752  Val Acc: 0.8672\n",
            "⚠️ No improvement in Val Acc for 4 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100 Training:   2%|▎                     | 2/120 [00:06<05:00,  2.55s/it, train_loss=0.0864]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:   7%|█▌                     | 8/120 [00:15<02:57,  1.58s/it, train_loss=0.103]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  12%|██▌                   | 14/120 [00:26<02:44,  1.55s/it, train_loss=0.237]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 11 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 12 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 13 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 14 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  15%|███▏                 | 18/120 [00:34<03:25,  2.01s/it, train_loss=0.0985]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 15 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 16 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 17 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 18 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  16%|███▍                  | 19/120 [00:38<03:47,  2.25s/it, train_loss=0.133]\n",
            "Validation after 20 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 20 batches:   0%|                            | 0/10 [00:04<?, ?it/s, val_loss=0.66]\u001b[A\n",
            "Validation after 20 batches:  10%|██                  | 1/10 [00:04<00:41,  4.59s/it, val_loss=0.66]\u001b[A\n",
            "Validation after 20 batches:  10%|██                  | 1/10 [00:04<00:41,  4.59s/it, val_loss=1.25]\u001b[A\n",
            "Validation after 20 batches:  20%|████                | 2/10 [00:04<00:15,  1.98s/it, val_loss=1.25]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 19 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:  20%|████▏                | 2/10 [00:10<00:15,  1.98s/it, val_loss=1.2]\u001b[A\n",
            "Validation after 20 batches:  30%|██████▎              | 3/10 [00:10<00:25,  3.59s/it, val_loss=1.2]\u001b[A\n",
            "Validation after 20 batches:  30%|█████▋             | 3/10 [00:10<00:25,  3.59s/it, val_loss=0.609]\u001b[A\n",
            "Validation after 20 batches:  40%|███████▌           | 4/10 [00:10<00:13,  2.25s/it, val_loss=0.609]\u001b[A\n",
            "Validation after 20 batches:  40%|████████            | 4/10 [00:14<00:13,  2.25s/it, val_loss=1.38]\u001b[A\n",
            "Validation after 20 batches:  50%|██████████          | 5/10 [00:14<00:14,  2.97s/it, val_loss=1.38]\u001b[A\n",
            "Validation after 20 batches:  50%|█████████▌         | 5/10 [00:14<00:14,  2.97s/it, val_loss=0.342]\u001b[A\n",
            "Validation after 20 batches:  60%|███████████▍       | 6/10 [00:14<00:07,  1.99s/it, val_loss=0.342]\u001b[A\n",
            "Validation after 20 batches:  60%|███████████▍       | 6/10 [00:16<00:07,  1.99s/it, val_loss=0.795]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:16<00:06,  2.02s/it, val_loss=0.795]\u001b[A\n",
            "Validation after 20 batches:  70%|█████████████▎     | 7/10 [00:16<00:06,  2.02s/it, val_loss=0.375]\u001b[A\n",
            "Validation after 20 batches:  80%|███████████████▏   | 8/10 [00:16<00:02,  1.42s/it, val_loss=0.375]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 20 batches:  80%|████████████████    | 8/10 [00:18<00:02,  1.42s/it, val_loss=0.21]\u001b[A\n",
            "Validation after 20 batches:  90%|██████████████████  | 9/10 [00:18<00:01,  1.60s/it, val_loss=0.21]\u001b[A\n",
            "Validation after 20 batches: 100%|███████████████████| 10/10 [00:19<00:00,  1.91s/it, val_loss=1.41]\n",
            "Epoch 8/100 Training:  17%|███▋                  | 20/120 [00:57<12:46,  7.66s/it, train_loss=0.133]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 20/120 batches: Val Loss: 0.2058  Val Acc: 0.7937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100 Training:  22%|████▎               | 26/120 [01:03<03:20,  2.14s/it, train_loss=0.00657]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 20 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 21 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 22 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 23 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 24 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 25 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 26 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  27%|█████▌               | 32/120 [01:15<02:34,  1.75s/it, train_loss=0.0257]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 27 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 28 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 29 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 30 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 31 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 32 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  32%|██████▎             | 38/120 [01:26<01:58,  1.44s/it, train_loss=0.00267]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 33 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 34 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 35 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 36 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 37 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 38 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  32%|██████▊              | 39/120 [01:32<03:30,  2.60s/it, train_loss=0.0323]\n",
            "Validation after 40 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 39 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:   0%|                           | 0/10 [00:05<?, ?it/s, val_loss=0.132]\u001b[A\n",
            "Validation after 40 batches:  10%|█▉                 | 1/10 [00:05<00:51,  5.67s/it, val_loss=0.132]\u001b[A\n",
            "Validation after 40 batches:  10%|█▉                 | 1/10 [00:05<00:51,  5.67s/it, val_loss=0.659]\u001b[A\n",
            "Validation after 40 batches:  20%|███▊               | 2/10 [00:05<00:19,  2.43s/it, val_loss=0.659]\u001b[A\n",
            "Validation after 40 batches:  20%|████                | 2/10 [00:08<00:19,  2.43s/it, val_loss=0.57]\u001b[A\n",
            "Validation after 40 batches:  30%|██████              | 3/10 [00:08<00:18,  2.63s/it, val_loss=0.57]\u001b[A\n",
            "Validation after 40 batches:  30%|████▊           | 3/10 [00:08<00:18,  2.63s/it, val_loss=0.000462]\u001b[A\n",
            "Validation after 40 batches:  40%|██████▍         | 4/10 [00:08<00:09,  1.64s/it, val_loss=0.000462]\u001b[A\n",
            "Validation after 40 batches:  40%|███████▌           | 4/10 [00:12<00:09,  1.64s/it, val_loss=0.485]\u001b[A\n",
            "Validation after 40 batches:  50%|█████████▌         | 5/10 [00:12<00:11,  2.35s/it, val_loss=0.485]\u001b[A\n",
            "Validation after 40 batches:  50%|████████▌        | 5/10 [00:12<00:11,  2.35s/it, val_loss=0.00324]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 40 batches:  50%|█████████▌         | 5/10 [00:16<00:11,  2.35s/it, val_loss=0.253]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:16<00:06,  2.17s/it, val_loss=0.253]\u001b[A\n",
            "Validation after 40 batches:  70%|█████████████▎     | 7/10 [00:16<00:06,  2.17s/it, val_loss=0.107]\u001b[A\n",
            "Validation after 40 batches:  80%|███████████████▏   | 8/10 [00:16<00:03,  1.62s/it, val_loss=0.107]\u001b[A\n",
            "Validation after 40 batches:  80%|███████████████▏   | 8/10 [00:18<00:03,  1.62s/it, val_loss=0.334]\u001b[A\n",
            "Validation after 40 batches:  90%|█████████████████  | 9/10 [00:18<00:01,  1.78s/it, val_loss=0.334]\u001b[A\n",
            "Validation after 40 batches: 100%|███████████████████| 10/10 [00:18<00:00,  1.89s/it, val_loss=0.96]\n",
            "Epoch 8/100 Training:  33%|███████              | 40/120 [01:50<10:04,  7.55s/it, train_loss=0.0323]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 40/120 batches: Val Loss: 0.0876  Val Acc: 0.9125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100 Training:  38%|███████▋            | 46/120 [01:55<02:02,  1.66s/it, train_loss=0.00354]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 40 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 41 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 42 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 43 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 44 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 45 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 46 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  42%|████████▊            | 50/120 [02:03<02:08,  1.84s/it, train_loss=0.0102]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 47 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 48 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 49 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 50 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  47%|█████████▊           | 56/120 [02:14<01:38,  1.54s/it, train_loss=0.0172]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 51 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 52 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 53 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 54 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 55 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 56 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  49%|█████████▎         | 59/120 [02:22<02:20,  2.30s/it, train_loss=0.000753]\n",
            "Validation after 60 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 60 batches:   0%|                           | 0/10 [00:04<?, ?it/s, val_loss=0.192]\u001b[A\n",
            "Validation after 60 batches:  10%|█▉                 | 1/10 [00:04<00:40,  4.51s/it, val_loss=0.192]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 57 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 58 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 59 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:  10%|█▉                 | 1/10 [00:04<00:40,  4.51s/it, val_loss=0.923]\u001b[A\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:04<00:15,  1.96s/it, val_loss=0.923]\u001b[A\n",
            "Validation after 60 batches:  20%|███▊               | 2/10 [00:09<00:15,  1.96s/it, val_loss=0.783]\u001b[A\n",
            "Validation after 60 batches:  30%|█████▋             | 3/10 [00:09<00:23,  3.39s/it, val_loss=0.783]\u001b[A\n",
            "Validation after 60 batches:  30%|█████            | 3/10 [00:09<00:23,  3.39s/it, val_loss=6.76e-5]\u001b[A\n",
            "Validation after 60 batches:  40%|██████▊          | 4/10 [00:09<00:12,  2.12s/it, val_loss=6.76e-5]\u001b[A\n",
            "Validation after 60 batches:  40%|███████▌           | 4/10 [00:13<00:12,  2.12s/it, val_loss=0.515]\u001b[A\n",
            "Validation after 60 batches:  50%|█████████▌         | 5/10 [00:13<00:13,  2.78s/it, val_loss=0.515]\u001b[A\n",
            "Validation after 60 batches:  50%|████████▌        | 5/10 [00:14<00:13,  2.78s/it, val_loss=0.00105]\u001b[A\n",
            "Validation after 60 batches:  60%|██████████▏      | 6/10 [00:14<00:07,  1.98s/it, val_loss=0.00105]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 60 batches:  60%|████████████        | 6/10 [00:16<00:07,  1.98s/it, val_loss=0.44]\u001b[A\n",
            "Validation after 60 batches:  70%|██████████████      | 7/10 [00:16<00:05,  1.93s/it, val_loss=0.44]\u001b[A\n",
            "Validation after 60 batches:  70%|█████████████▎     | 7/10 [00:16<00:05,  1.93s/it, val_loss=0.122]\u001b[A\n",
            "Validation after 60 batches:  80%|███████████████▏   | 8/10 [00:16<00:02,  1.44s/it, val_loss=0.122]\u001b[A\n",
            "Validation after 60 batches:  80%|███████████████▏   | 8/10 [00:18<00:02,  1.44s/it, val_loss=0.483]\u001b[A\n",
            "Validation after 60 batches:  90%|█████████████████  | 9/10 [00:18<00:01,  1.54s/it, val_loss=0.483]\u001b[A\n",
            "Validation after 60 batches:  90%|██████████████████  | 9/10 [00:18<00:01,  1.54s/it, val_loss=1.35]\u001b[A\n",
            "Validation after 60 batches: 100%|███████████████████| 10/10 [00:18<00:00,  1.86s/it, val_loss=1.35]\n",
            "Epoch 8/100 Training:  50%|█████████▌         | 60/120 [02:41<07:16,  7.27s/it, train_loss=0.000753]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 60/120 batches: Val Loss: 0.1201  Val Acc: 0.9187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100 Training:  54%|██████████▎        | 65/120 [02:45<02:05,  2.28s/it, train_loss=0.000469]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 60 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 61 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 62 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 63 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 64 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 65 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  59%|█████████████         | 71/120 [02:56<01:33,  1.91s/it, train_loss=0.183]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 66 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 67 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 68 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 69 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 70 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 71 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  63%|█████████████▎       | 76/120 [03:06<01:16,  1.75s/it, train_loss=0.0385]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 72 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 73 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 74 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 75 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 76 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  66%|████████████▌      | 79/120 [03:14<01:23,  2.04s/it, train_loss=0.000875]\n",
            "Validation after 80 batches:   0%|                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 77 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 78 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 79 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 80 batches:   0%|                            | 0/10 [00:06<?, ?it/s, val_loss=0.12]\u001b[A\n",
            "Validation after 80 batches:  10%|██                  | 1/10 [00:06<00:55,  6.16s/it, val_loss=0.12]\u001b[A\n",
            "Validation after 80 batches:  10%|█▉                 | 1/10 [00:06<00:55,  6.16s/it, val_loss=0.775]\u001b[A\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:06<00:20,  2.61s/it, val_loss=0.775]\u001b[A\n",
            "Validation after 80 batches:  20%|███▊               | 2/10 [00:10<00:20,  2.61s/it, val_loss=0.485]\u001b[A\n",
            "Validation after 80 batches:  30%|█████▋             | 3/10 [00:10<00:22,  3.16s/it, val_loss=0.485]\u001b[A\n",
            "Validation after 80 batches:  30%|████▊           | 3/10 [00:10<00:22,  3.16s/it, val_loss=0.000645]\u001b[A\n",
            "Validation after 80 batches:  40%|██████▍         | 4/10 [00:10<00:11,  1.98s/it, val_loss=0.000645]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 80 batches:  40%|███████▌           | 4/10 [00:13<00:11,  1.98s/it, val_loss=0.437]\u001b[A\n",
            "Validation after 80 batches:  50%|█████████▌         | 5/10 [00:13<00:12,  2.48s/it, val_loss=0.437]\u001b[A\n",
            "Validation after 80 batches:  50%|████████▌        | 5/10 [00:13<00:12,  2.48s/it, val_loss=0.00313]\u001b[A\n",
            "Validation after 80 batches:  60%|██████████▏      | 6/10 [00:13<00:06,  1.67s/it, val_loss=0.00313]\u001b[A\n",
            "Validation after 80 batches:  60%|██████████▊       | 6/10 [00:17<00:06,  1.67s/it, val_loss=0.0678]\u001b[A\n",
            "Validation after 80 batches:  70%|████████████▌     | 7/10 [00:17<00:06,  2.29s/it, val_loss=0.0678]\u001b[A\n",
            "Validation after 80 batches:  70%|█████████████▎     | 7/10 [00:17<00:06,  2.29s/it, val_loss=0.153]\u001b[A\n",
            "Validation after 80 batches:  80%|███████████████▏   | 8/10 [00:17<00:03,  1.60s/it, val_loss=0.153]\u001b[A\n",
            "Validation after 80 batches:  80%|███████████████▏   | 8/10 [00:20<00:03,  1.60s/it, val_loss=0.744]\u001b[A\n",
            "Validation after 80 batches:  90%|█████████████████  | 9/10 [00:20<00:01,  1.95s/it, val_loss=0.744]\u001b[A\n",
            "Validation after 80 batches: 100%|███████████████████| 10/10 [00:20<00:00,  2.03s/it, val_loss=1.02]\n",
            "Epoch 8/100 Training:  67%|████████████▋      | 80/120 [03:34<05:13,  7.84s/it, train_loss=0.000875]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 80/120 batches: Val Loss: 0.0950  Val Acc: 0.9062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100 Training:  70%|███████████████▍      | 84/120 [03:35<01:14,  2.07s/it, train_loss=0.016]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 80 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 81 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 82 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 83 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 84 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  74%|███████████████▌     | 89/120 [03:43<00:45,  1.47s/it, train_loss=0.0179]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 85 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 86 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 87 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 88 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 89 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  78%|█████████████████▏    | 94/120 [03:56<00:58,  2.27s/it, train_loss=0.009]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 90 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 91 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 92 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 93 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 94 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  82%|████████████████▎   | 98/120 [04:04<00:43,  1.98s/it, train_loss=0.00349]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 95 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 96 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 97 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 98 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  82%|██████████████████▏   | 99/120 [04:07<00:47,  2.27s/it, train_loss=0.113]\n",
            "Validation after 100 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 100 batches:   0%|                          | 0/10 [00:04<?, ?it/s, val_loss=0.149]\u001b[A\n",
            "Validation after 100 batches:  10%|█▊                | 1/10 [00:04<00:41,  4.59s/it, val_loss=0.149]\u001b[A\n",
            "Validation after 100 batches:  10%|█▊                | 1/10 [00:04<00:41,  4.59s/it, val_loss=0.193]\u001b[A\n",
            "Validation after 100 batches:  20%|███▌              | 2/10 [00:04<00:15,  1.98s/it, val_loss=0.193]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 99 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 100 batches:  20%|███▍             | 2/10 [00:10<00:15,  1.98s/it, val_loss=0.0352]\u001b[A\n",
            "Validation after 100 batches:  30%|█████            | 3/10 [00:10<00:26,  3.73s/it, val_loss=0.0352]\u001b[A\n",
            "Validation after 100 batches:  30%|████▊           | 3/10 [00:10<00:26,  3.73s/it, val_loss=6.47e-5]\u001b[A\n",
            "Validation after 100 batches:  40%|██████▍         | 4/10 [00:10<00:14,  2.35s/it, val_loss=6.47e-5]\u001b[A\n",
            "Validation after 100 batches:  40%|███████▏          | 4/10 [00:14<00:14,  2.35s/it, val_loss=0.138]\u001b[A\n",
            "Validation after 100 batches:  50%|█████████         | 5/10 [00:14<00:13,  2.68s/it, val_loss=0.138]\u001b[A\n",
            "Validation after 100 batches:  50%|████████        | 5/10 [00:14<00:13,  2.68s/it, val_loss=1.87e-5]\u001b[A\n",
            "Validation after 100 batches:  60%|█████████▌      | 6/10 [00:14<00:07,  1.81s/it, val_loss=1.87e-5]\u001b[A\n",
            "Validation after 100 batches:  60%|██████████▊       | 6/10 [00:16<00:07,  1.81s/it, val_loss=0.174]\u001b[A\n",
            "Validation after 100 batches:  70%|████████████▌     | 7/10 [00:16<00:05,  1.91s/it, val_loss=0.174]\u001b[A\n",
            "Validation after 100 batches:  70%|███████████▉     | 7/10 [00:16<00:05,  1.91s/it, val_loss=0.0859]\u001b[A\n",
            "Validation after 100 batches:  80%|█████████████▌   | 8/10 [00:16<00:02,  1.34s/it, val_loss=0.0859]\u001b[A\n",
            "Validation after 100 batches:  80%|████████████████    | 8/10 [00:18<00:02,  1.34s/it, val_loss=1.3]\u001b[A\n",
            "Validation after 100 batches:  90%|██████████████████  | 9/10 [00:18<00:01,  1.53s/it, val_loss=1.3]\u001b[A\n",
            "Validation after 100 batches: 100%|█████████████████| 10/10 [00:18<00:00,  1.85s/it, val_loss=0.512]\n",
            "Epoch 8/100 Training:  83%|█████████████████▌   | 100/120 [04:26<02:24,  7.23s/it, train_loss=0.113]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 100/120 batches: Val Loss: 0.0648  Val Acc: 0.9437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100 Training:  87%|████████████████▍  | 104/120 [04:27<00:30,  1.92s/it, train_loss=0.00137]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 101 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 102 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 103 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 104 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  89%|████████████████  | 107/120 [04:37<00:35,  2.75s/it, train_loss=0.000198]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 105 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 106 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 107 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  93%|███████████████████▌ | 112/120 [04:44<00:12,  1.60s/it, train_loss=0.261]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 108 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 109 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 110 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 111 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 112 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  98%|██████████████████▋| 118/120 [04:56<00:03,  1.72s/it, train_loss=0.00277]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 113 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 114 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 115 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 116 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 117 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 118 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Training:  99%|███████████████████▊| 119/120 [05:00<00:02,  2.23s/it, train_loss=0.0209]\n",
            "Validation after 120 batches:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation after 120 batches:   0%|                         | 0/10 [00:03<?, ?it/s, val_loss=0.0337]\u001b[A\n",
            "Validation after 120 batches:  10%|█▋               | 1/10 [00:03<00:29,  3.27s/it, val_loss=0.0337]\u001b[A\n",
            "Validation after 120 batches:  10%|█▊                | 1/10 [00:03<00:29,  3.27s/it, val_loss=0.306]\u001b[A\n",
            "Validation after 120 batches:  10%|█▊                | 1/10 [00:05<00:29,  3.27s/it, val_loss=0.216]\u001b[A\n",
            "Validation after 120 batches:  30%|█████▍            | 3/10 [00:05<00:11,  1.65s/it, val_loss=0.216]\u001b[A\n",
            "Validation after 120 batches:  30%|████▌          | 3/10 [00:05<00:11,  1.65s/it, val_loss=0.000366]\u001b[A\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 119 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\n",
            "Validation after 120 batches:  30%|██████              | 3/10 [00:07<00:11,  1.65s/it, val_loss=0.2]\u001b[A\n",
            "Validation after 120 batches:  50%|██████████          | 5/10 [00:07<00:06,  1.36s/it, val_loss=0.2]\u001b[A\n",
            "Validation after 120 batches:  50%|███████▌       | 5/10 [00:07<00:06,  1.36s/it, val_loss=0.000124]\u001b[A\n",
            "Validation after 120 batches:  60%|█████████      | 6/10 [00:07<00:04,  1.02s/it, val_loss=0.000124]\u001b[A\n",
            "Validation after 120 batches:  60%|██████████▊       | 6/10 [00:09<00:04,  1.02s/it, val_loss=0.053]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:09<00:03,  1.32s/it, val_loss=0.053]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:09<00:03,  1.32s/it, val_loss=0.229]\u001b[A\n",
            "Validation after 120 batches:  70%|████████████▌     | 7/10 [00:11<00:03,  1.32s/it, val_loss=0.561]\u001b[A\n",
            "Validation after 120 batches:  90%|████████████████▏ | 9/10 [00:11<00:01,  1.17s/it, val_loss=0.561]\u001b[A\n",
            "Validation after 120 batches: 100%|█████████████████| 10/10 [00:11<00:00,  1.19s/it, val_loss=0.416]\n",
            "Epoch 8/100 Training: 100%|████████████████████| 120/120 [05:12<00:00,  2.60s/it, train_loss=0.0209]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation after 120/120 batches: Val Loss: 0.0503  Val Acc: 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100 Validation:   5%|█▏                      | 2/40 [00:03<01:00,  1.60s/it, val_loss=0.306]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 5 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 6 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 7 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 8 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 9 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 10 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 120 that is less than the current step 400. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/100 Validation: 100%|████████████████████████| 40/40 [01:19<00:00,  1.99s/it, val_loss=0.92]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/100] Train Loss: 0.0526  Train Acc: 0.9797 Val Loss: 0.4044  Val Acc: 0.8750\n",
            "⚠️ No improvement in Val Acc for 5 epoch(s).\n",
            "⏹ Early stopping triggered! Training stopped.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import wandb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Initialize wandb for logging\n",
        "wandb.init(project=\"Retinal_Diseases\")\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize variables for calculating the loss and accuracy\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# Use tqdm for the test loop\n",
        "test_loader_tqdm = tqdm(test_loader, desc=\"Testing\", ncols=100)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader_tqdm:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device).unsqueeze(1)  # Ensure labels are the correct shape\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item() * images.size(0)\n",
        "\n",
        "        preds = torch.sigmoid(outputs) > 0.5  # threshold 0.5 for binary classification\n",
        "        correct += (preds == labels.bool()).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # Store predictions and labels for confusion matrix\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Update the tqdm progress bar with the current loss\n",
        "        test_loader_tqdm.set_postfix(test_loss=loss.item())\n",
        "\n",
        "# Calculate average test loss and accuracy\n",
        "test_loss /= len(test_loader.dataset)\n",
        "test_acc = correct / total\n",
        "\n",
        "# Log the test loss and accuracy to WandB\n",
        "wandb.log({'test_loss': test_loss, 'test_accuracy': test_acc})\n",
        "\n",
        "# Print out test results\n",
        "print(f\"Test Loss: {test_loss:.4f}  Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "collapsed": true,
        "id": "yL0QUXeDtHrA",
        "outputId": "b328988d-46cb-48fa-cb9e-41aa848263bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy_epoch</td><td>▁▃▅▆▇██</td></tr><tr><td>train_loss_batch</td><td>█▃█▆▆▄▄▄▆▂▃▃▆▃▂▄▂▄▂▂▂▅▃▁▁▁▁▁▂▁▁▁▂▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▂▁▁</td></tr><tr><td>val_accuracy_epoch</td><td>▁█▄▁█▇▇</td></tr><tr><td>val_loss_batch</td><td>▂▂▂▂▂▃▂▁▁▁▂▂▁▁▂▁▁▁▃▃▂▂▂▂▁▂▂▁▇▂▂▂▂▅▂█▁▁▃▂</td></tr><tr><td>val_loss_epoch</td><td>▂▁▄█▃▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy_epoch</td><td>0.9875</td></tr><tr><td>train_loss_batch</td><td>0.0618</td></tr><tr><td>train_loss_epoch</td><td>0.03707</td></tr><tr><td>val_accuracy_epoch</td><td>0.88438</td></tr><tr><td>val_loss_batch</td><td>0.78891</td></tr><tr><td>val_loss_epoch</td><td>0.45248</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">devout-cherry-2</strong> at: <a href='https://wandb.ai/jeevan-neupane002-nepal-applied-/Eye_Disease_Prediction/runs/johiqmys' target=\"_blank\">https://wandb.ai/jeevan-neupane002-nepal-applied-/Eye_Disease_Prediction/runs/johiqmys</a><br> View project at: <a href='https://wandb.ai/jeevan-neupane002-nepal-applied-/Eye_Disease_Prediction' target=\"_blank\">https://wandb.ai/jeevan-neupane002-nepal-applied-/Eye_Disease_Prediction</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250428_064543-johiqmys/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250428_074942-109f8bgg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jeevan-neupane002-nepal-applied-/Retinal_Diseases/runs/109f8bgg' target=\"_blank\">likely-elevator-3</a></strong> to <a href='https://wandb.ai/jeevan-neupane002-nepal-applied-/Retinal_Diseases' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jeevan-neupane002-nepal-applied-/Retinal_Diseases' target=\"_blank\">https://wandb.ai/jeevan-neupane002-nepal-applied-/Retinal_Diseases</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jeevan-neupane002-nepal-applied-/Retinal_Diseases/runs/109f8bgg' target=\"_blank\">https://wandb.ai/jeevan-neupane002-nepal-applied-/Retinal_Diseases/runs/109f8bgg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|█████████████████████████████████████| 40/40 [06:29<00:00,  9.75s/it, test_loss=0.672]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.2640  Test Accuracy: 0.9203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\"], yticklabels=[\"Class 0\", \"Class 1\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Fv_lqLDvwWZe",
        "outputId": "2d0422be-b1b1-4eb3-ee4b-9faa46ae6317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming `all_labels` and `all_preds` are your true labels and predicted labels respectively\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\"], yticklabels=[\"Class 0\", \"Class 1\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Now, calculate the performance metrics\n",
        "TP = cm[1, 1]  # True Positives\n",
        "TN = cm[0, 0]  # True Negatives\n",
        "FP = cm[0, 1]  # False Positives\n",
        "FN = cm[1, 0]  # False Negatives\n",
        "\n",
        "# Accuracy\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "\n",
        "# Precision\n",
        "precision = TP / (TP + FP)\n",
        "\n",
        "# Recall\n",
        "recall = TP / (TP + FN)\n",
        "\n",
        "# F1-Score\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Log the metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "91_Jhi6bwuh7",
        "outputId": "524454a2-a58e-4ce3-ef53-840561686815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9203\n",
            "Precision: 0.9505\n",
            "Recall: 0.9486\n",
            "F1-Score: 0.9496\n"
          ]
        }
      ]
    }
  ]
}